{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "wyIwW5TnyjlZ",
      "metadata": {
        "id": "wyIwW5TnyjlZ"
      },
      "source": [
        "# Importing Contigencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZEM2wpQNmyY2",
      "metadata": {
        "collapsed": true,
        "id": "ZEM2wpQNmyY2"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade torch torchvision timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hCbIVvFEneTA",
      "metadata": {
        "collapsed": true,
        "id": "hCbIVvFEneTA"
      },
      "outputs": [],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sSsHzrGi4Qsh",
      "metadata": {
        "id": "sSsHzrGi4Qsh"
      },
      "outputs": [],
      "source": [
        "!pip install grad-cam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bdba979-bc93-4446-98e7-27bc72966eac",
      "metadata": {
        "id": "2bdba979-bc93-4446-98e7-27bc72966eac"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import random\n",
        "from collections import defaultdict\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "from torchvision import transforms, models\n",
        "from scipy.ndimage import gaussian_filter, map_coordinates\n",
        "import torchvision.transforms.functional as TF\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torchvision.models as models\n",
        "import warnings\n",
        "import timm\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import traceback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Hk_2wOvTzdbc",
      "metadata": {
        "id": "Hk_2wOvTzdbc"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bbe62b3",
      "metadata": {
        "id": "2bbe62b3"
      },
      "source": [
        "# Data preprocessing\n",
        "## 1) Unzipping the MRI Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3dfc568",
      "metadata": {
        "id": "e3dfc568"
      },
      "outputs": [],
      "source": [
        "# Path to your zip file\n",
        "zip_path = '/content/drive/My Drive/Colab Notebooks/mri_images.zip'\n",
        "# Create a directory to extract the files\n",
        "extract_path = '/content/mri_images'\n",
        "os.makedirs(extract_path, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bKm8-NADMa9o",
      "metadata": {
        "id": "bKm8-NADMa9o"
      },
      "outputs": [],
      "source": [
        "# Get the name of the zip file without the path\n",
        "zip_filename = os.path.basename(zip_path)\n",
        "\n",
        "# Get the name of the extracted folder (remove .zip extension)\n",
        "extracted_folder = os.path.splitext(zip_filename)[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2f5c440",
      "metadata": {
        "collapsed": true,
        "id": "b2f5c440"
      },
      "outputs": [],
      "source": [
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n",
        "print(f\"Zip file: {zip_filename}\")\n",
        "print(f\"Extracted folder: {extracted_folder}\")\n",
        "print(f\"Files extracted to: {extract_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9925b00",
      "metadata": {
        "id": "f9925b00"
      },
      "outputs": [],
      "source": [
        "# Define the path to the glioma folder\n",
        "glioma_path = os.path.join('Testing', 'glioma')\n",
        "\n",
        "# Verify the path exists\n",
        "if os.path.exists(glioma_path):\n",
        "    print(f\"Successfully located the glioma folder at: {glioma_path}\")\n",
        "else:\n",
        "    print(\"Couldn't find the glioma folder. Please check the path.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e4425e5",
      "metadata": {
        "id": "9e4425e5"
      },
      "source": [
        "#### Viewing a Random Image:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be853e2e",
      "metadata": {
        "collapsed": true,
        "id": "be853e2e"
      },
      "outputs": [],
      "source": [
        "# Get a list of all image files in the glioma folder\n",
        "image_files = [f for f in os.listdir(glioma_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "if image_files:\n",
        "    # Select a random image\n",
        "    random_image = random.choice(image_files)\n",
        "    image_path = os.path.join(glioma_path, random_image)\n",
        "\n",
        "    # Open and display the image\n",
        "    img = Image.open(image_path)\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Sample Glioma Image: {random_image}\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No image files found in the glioma folder.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8f7a8d6",
      "metadata": {
        "collapsed": true,
        "id": "f8f7a8d6"
      },
      "outputs": [],
      "source": [
        "# Get a list of all image files in the glioma folder\n",
        "image_files = [f for f in os.listdir(glioma_path) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "if image_files:\n",
        "    # Select a random image\n",
        "    random_image = random.choice(image_files)\n",
        "    image_path = os.path.join(glioma_path, random_image)\n",
        "\n",
        "    # Open the image\n",
        "    img = Image.open(image_path)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = np.array(img)\n",
        "\n",
        "    # Display the image\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(img_array, cmap='gray')  # Use 'gray' colormap\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Sample Glioma Image: {random_image}\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No image files found in the glioma folder.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "575c4bb2",
      "metadata": {
        "id": "575c4bb2"
      },
      "source": [
        "## 2) Resizing all the images to ResNet-50 input size and Saving them in a new folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92deaabc",
      "metadata": {
        "id": "92deaabc"
      },
      "outputs": [],
      "source": [
        "def resize_images(input_folder, output_folder, target_size=(224, 224)):\n",
        "    \"\"\"\n",
        "    Resize all images in the input folder and save them to the output folder.\n",
        "\n",
        "    Args:\n",
        "    input_folder (str): Path to the folder containing original images\n",
        "    output_folder (str): Path to the folder where resized images will be saved\n",
        "    target_size (tuple): The target size for the images (width, height)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "            try:\n",
        "                img = Image.open(os.path.join(input_folder, filename))\n",
        "                img = img.resize(target_size, Image.LANCZOS)\n",
        "                img.save(os.path.join(output_folder, filename))\n",
        "                print(f\"Resized {filename}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {str(e)}\")\n",
        "\n",
        "# Define the size you want for all images\n",
        "target_size = (224, 224)  # This is a common size for many CNN architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "655a34c8",
      "metadata": {
        "collapsed": true,
        "id": "655a34c8"
      },
      "outputs": [],
      "source": [
        "# Define the base directories\n",
        "base_input_dir = 'Training'  # Adjust this if your folder structure is different\n",
        "base_output_dir = '/content/drive/MyDrive/Colab Notebooks/Resized_Training'\n",
        "\n",
        "# List of tumor types\n",
        "tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "# Resize images for each tumor type\n",
        "for tumor_type in tumor_types:\n",
        "    input_folder = os.path.join(base_input_dir, tumor_type)\n",
        "    output_folder = os.path.join(base_output_dir, tumor_type)\n",
        "\n",
        "    print(f\"Resizing images in {tumor_type} folder...\")\n",
        "    resize_images(input_folder, output_folder, target_size)\n",
        "\n",
        "print(\"Image resizing complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zC4nD9LUaOde",
      "metadata": {
        "collapsed": true,
        "id": "zC4nD9LUaOde"
      },
      "outputs": [],
      "source": [
        "# Define the base directories\n",
        "base_input_dir = 'Testing'  # Adjust this if your folder structure is different\n",
        "base_output_dir = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "\n",
        "# List of tumor types\n",
        "tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "# Resize images for each tumor type\n",
        "for tumor_type in tumor_types:\n",
        "    input_folder = os.path.join(base_input_dir, tumor_type)\n",
        "    output_folder = os.path.join(base_output_dir, tumor_type)\n",
        "\n",
        "    print(f\"Resizing images in {tumor_type} folder...\")\n",
        "    resize_images(input_folder, output_folder, target_size)\n",
        "\n",
        "print(\"Image resizing complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UlXDjPjnaF0V",
      "metadata": {
        "id": "UlXDjPjnaF0V"
      },
      "source": [
        "### Loading the resized folders from google drive:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-p9pcBvbTcOT",
      "metadata": {
        "collapsed": true,
        "id": "-p9pcBvbTcOT"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive if not already mounted\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Define the base directory in Google Drive\n",
        "base_output_dir = '/content/drive/MyDrive/Colab Notebooks/Resized_Training'\n",
        "\n",
        "# List of tumor types\n",
        "tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "# Choose a random tumor type and image\n",
        "tumor_type = random.choice(tumor_types)\n",
        "resized_folder = os.path.join(base_output_dir, tumor_type)\n",
        "\n",
        "# Check if the folder exists\n",
        "if not os.path.exists(resized_folder):\n",
        "    print(f\"Error: The folder {resized_folder} does not exist in your Google Drive.\")\n",
        "else:\n",
        "    image_files = [f for f in os.listdir(resized_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"Error: No image files found in {resized_folder}\")\n",
        "    else:\n",
        "        random_image = random.choice(image_files)\n",
        "\n",
        "        # Display the image\n",
        "        img_path = os.path.join(resized_folder, random_image)\n",
        "        img = Image.open(img_path)\n",
        "        img_array = np.array(img)\n",
        "\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(img_array, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Resized {tumor_type} Image: {random_image}\\nSize: {img_array.shape}\")\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Image size: {img_array.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SB008AFDbJ16",
      "metadata": {
        "collapsed": true,
        "id": "SB008AFDbJ16"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive if not already mounted\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Define the base directory in Google Drive\n",
        "base_output_dir = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "\n",
        "# List of tumor types\n",
        "tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "# Choose a random tumor type and image\n",
        "tumor_type = random.choice(tumor_types)\n",
        "resized_folder = os.path.join(base_output_dir, tumor_type)\n",
        "\n",
        "# Check if the folder exists\n",
        "if not os.path.exists(resized_folder):\n",
        "    print(f\"Error: The folder {resized_folder} does not exist in your Google Drive.\")\n",
        "else:\n",
        "    image_files = [f for f in os.listdir(resized_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp'))]\n",
        "\n",
        "    if not image_files:\n",
        "        print(f\"Error: No image files found in {resized_folder}\")\n",
        "    else:\n",
        "        random_image = random.choice(image_files)\n",
        "\n",
        "        # Display the image\n",
        "        img_path = os.path.join(resized_folder, random_image)\n",
        "        img = Image.open(img_path)\n",
        "        img_array = np.array(img)\n",
        "\n",
        "        plt.figure(figsize=(8, 8))\n",
        "        plt.imshow(img_array, cmap='gray')\n",
        "        plt.axis('off')\n",
        "        plt.title(f\"Resized {tumor_type} Image: {random_image}\\nSize: {img_array.shape}\")\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"Image size: {img_array.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xkbckuT3y-Jd",
      "metadata": {
        "id": "xkbckuT3y-Jd"
      },
      "source": [
        "# PyTorch Data Pre-Processing\n",
        "\n",
        "## 1) DataSet & DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "MJujwySKzRis",
      "metadata": {
        "id": "MJujwySKzRis"
      },
      "source": [
        "Defining the data sets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Mc-By-K9pST7",
      "metadata": {
        "id": "Mc-By-K9pST7"
      },
      "outputs": [],
      "source": [
        "test_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "train_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Training'\n",
        "tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BES8ulaozTmz",
      "metadata": {
        "id": "BES8ulaozTmz"
      },
      "source": [
        "DataSet Class:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66863b94",
      "metadata": {
        "id": "66863b94"
      },
      "source": [
        "## 2) Data Augmentation\n",
        "\n",
        "1. Random Crop\n",
        "2. Random Flip\n",
        "3. Random Rotate\n",
        "4. Random Brightness\n",
        "5. Random Contrast\n",
        "6. On the fly augmentation during training (saves memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rd1WSxuFCMrx",
      "metadata": {
        "id": "rd1WSxuFCMrx"
      },
      "source": [
        "__Important__\n",
        "\n",
        "1) Avoid extreme rotations or flips that could change the anatomical orientation.\n",
        "\n",
        "2) Be cautious with color-based augmentations, as MRI intensity values often have specific meanings.\n",
        "\n",
        "3)Maintain the overall structure and proportions of the brain."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AEm0XQZMCghb",
      "metadata": {
        "id": "AEm0XQZMCghb"
      },
      "source": [
        "1. Slight rotations (within ±10 degrees)\n",
        "2. Small shifts (translations)\n",
        "3. Zoom in/out (within a small range)\n",
        "4. Minimal brightness and contrast adjustments\n",
        "5. Gaussian noise addition (to simulate image noise)\n",
        "6. Elastic deformations (subtle warping)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0ePbW7TwvLv",
      "metadata": {
        "id": "c0ePbW7TwvLv"
      },
      "outputs": [],
      "source": [
        "class RandomMRIAugmentation(nn.Module):\n",
        "    def __init__(self, rotation_range=10, translation_range=0.1, zoom_range=0.1, noise_factor=0.05, p=0.5):\n",
        "        super().__init__()\n",
        "        self.rotation_range = rotation_range\n",
        "        self.translation_range = translation_range\n",
        "        self.zoom_range = zoom_range\n",
        "        self.noise_factor = noise_factor\n",
        "        self.p = p  # Probability of applying each augmentation\n",
        "\n",
        "    def forward(self, img):\n",
        "        # Ensure input is a tensor\n",
        "        if not isinstance(img, torch.Tensor):\n",
        "            img = TF.to_tensor(img)\n",
        "\n",
        "        # Random rotation\n",
        "        if random.random() < self.p:\n",
        "            angle = random.uniform(-self.rotation_range, self.rotation_range)\n",
        "            img = TF.rotate(img, angle)\n",
        "\n",
        "        # Random translation\n",
        "        if random.random() < self.p:\n",
        "            translate = [random.uniform(-self.translation_range, self.translation_range) for _ in range(2)]\n",
        "            img = TF.affine(img, angle=0, translate=translate, scale=1, shear=0)\n",
        "\n",
        "        # Random zoom\n",
        "        if random.random() < self.p:\n",
        "            scale = random.uniform(1-self.zoom_range, 1+self.zoom_range)\n",
        "            img = TF.affine(img, angle=0, translate=(0,0), scale=scale, shear=0)\n",
        "\n",
        "        # Add Gaussian noise\n",
        "        if random.random() < self.p:\n",
        "            noise = torch.randn_like(img) * self.noise_factor\n",
        "            img = img + noise\n",
        "            img = torch.clamp(img, 0, 1)\n",
        "\n",
        "        return img\n",
        "\n",
        "def elastic_transform(image, alpha=1000, sigma=30, alpha_affine=30):\n",
        "    \"\"\"Elastic deformation of images as described in [Simard2003].\"\"\"\n",
        "    random_state = np.random.RandomState(None)\n",
        "\n",
        "    shape = image.shape\n",
        "    shape_size = shape[:2]\n",
        "\n",
        "    # Random affine\n",
        "    center_square = np.float32(shape_size) // 2\n",
        "    square_size = min(shape_size) // 3\n",
        "    pts1 = np.float32([center_square + square_size, [center_square[0]+square_size, center_square[1]-square_size], center_square - square_size])\n",
        "    pts2 = pts1 + random_state.uniform(-alpha_affine, alpha_affine, size=pts1.shape).astype(np.float32)\n",
        "    M = cv2.getAffineTransform(pts1, pts2)\n",
        "    image = cv2.warpAffine(image, M, shape_size[::-1], borderMode=cv2.BORDER_REFLECT_101)\n",
        "\n",
        "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1), sigma) * alpha\n",
        "\n",
        "    x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
        "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
        "\n",
        "    return map_coordinates(image, indices, order=1, mode='reflect').reshape(shape)\n",
        "\n",
        "class RandomElasticDeformation(nn.Module):\n",
        "    def __init__(self, p=0.2, alpha=1000, sigma=30, alpha_affine=30):\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "        self.alpha = alpha\n",
        "        self.sigma = sigma\n",
        "        self.alpha_affine = alpha_affine\n",
        "\n",
        "    def forward(self, img):\n",
        "        if random.random() < self.p:\n",
        "            if isinstance(img, torch.Tensor):\n",
        "                img = img.numpy()\n",
        "            img = elastic_transform(img, self.alpha, self.sigma, self.alpha_affine)\n",
        "            img = torch.from_numpy(img)\n",
        "        return img\n",
        "\n",
        "def get_mri_augmentation(p_transform=0.5, p_elastic=0.2):\n",
        "    return transforms.Compose([\n",
        "        RandomMRIAugmentation(rotation_range=10, translation_range=0.1, zoom_range=0.1, noise_factor=0.05, p=p_transform),\n",
        "        RandomElasticDeformation(p=p_elastic),\n",
        "        transforms.Normalize(mean=[0.485], std=[0.229])  # Adjust these values based on your MRI data statistics\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "AE-Cp55NC_1Y",
      "metadata": {
        "id": "AE-Cp55NC_1Y"
      },
      "outputs": [],
      "source": [
        "class MRIDataset(Dataset):\n",
        "    def __init__(self, folder_path, tumor_types, transform=None, augment=False):\n",
        "        self.folder_path = folder_path\n",
        "        self.tumor_types = tumor_types\n",
        "        self.transform = transform\n",
        "        self.augment = augment\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "\n",
        "        for label, tumor_type in enumerate(tumor_types):\n",
        "            tumor_folder = os.path.join(folder_path, tumor_type)\n",
        "            for img_name in os.listdir(tumor_folder):\n",
        "                self.image_paths.append(os.path.join(tumor_folder, img_name))\n",
        "                self.labels.append(label)\n",
        "\n",
        "        if self.augment:\n",
        "            self.aug_transform = get_mri_augmentation(p_transform=0.5, p_elastic=0.2)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.augment:\n",
        "            image = self.aug_transform(image)\n",
        "        elif self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gJiXsfrYy5z0",
      "metadata": {
        "id": "gJiXsfrYy5z0"
      },
      "outputs": [],
      "source": [
        "def create_mri_datasets(train_folder, test_folder, tumor_types, val_split=0.2, batch_size=32):\n",
        "    # Define base transform for validation and test sets\n",
        "    base_transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485], std=[0.229])  # Adjust based on your MRI data\n",
        "    ])\n",
        "\n",
        "    # Create datasets\n",
        "    full_train_dataset = MRIDataset(train_folder, tumor_types, augment=True)\n",
        "    test_dataset = MRIDataset(test_folder, tumor_types, transform=base_transform)\n",
        "\n",
        "    # Split the training dataset into train and validation\n",
        "    train_indices, val_indices = train_test_split(\n",
        "        range(len(full_train_dataset)),\n",
        "        test_size=val_split,\n",
        "        stratify=full_train_dataset.labels,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    train_dataset = torch.utils.data.Subset(full_train_dataset, train_indices)\n",
        "    val_dataset = torch.utils.data.Subset(full_train_dataset, val_indices)\n",
        "\n",
        "    # Override the transform for the validation set\n",
        "    val_dataset.dataset.augment = False\n",
        "    val_dataset.dataset.transform = base_transform\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uihuQoeVy85r",
      "metadata": {
        "collapsed": true,
        "id": "uihuQoeVy85r"
      },
      "outputs": [],
      "source": [
        "# Usage\n",
        "train_loader, val_loader, test_loader = create_mri_datasets(train_folder, test_folder, tumor_types)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZYSUMhdwfOY-",
      "metadata": {
        "id": "ZYSUMhdwfOY-"
      },
      "source": [
        "# ResNets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vhIU243IzIoS",
      "metadata": {
        "id": "vhIU243IzIoS"
      },
      "source": [
        "\n",
        "## Model 1: ResNet50"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kvtM9IHZ1DsW",
      "metadata": {
        "id": "kvtM9IHZ1DsW"
      },
      "source": [
        "Defining the model:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TPjQzy9bCpol",
      "metadata": {
        "id": "TPjQzy9bCpol"
      },
      "outputs": [],
      "source": [
        "def initialize_resnet50_model(num_classes):\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    return model\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=100, patience=10):\n",
        "    start_time = time.time()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_acc = 0.0\n",
        "    epochs_no_improve = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_acc = train_correct / train_total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "             best_val_loss = val_loss\n",
        "             best_val_acc = val_acc\n",
        "             epochs_no_improve = 0\n",
        "             best_model = model.state_dict()\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve == patience:\n",
        "            print('Early stopping!')\n",
        "            model.load_state_dict(best_model)\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    return model, best_val_acc, training_time\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8x_TJ816mZj4",
      "metadata": {
        "id": "8x_TJ816mZj4"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader, tumor_types):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "    total_loss = 0.0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_probs = np.array(all_probs)\n",
        "\n",
        "    accuracy = (all_preds == all_labels).mean()\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "    auc_roc = roc_auc_score(all_labels, all_probs, average='weighted', multi_class='ovr')\n",
        "    avg_loss = total_loss / len(test_loader.dataset)\n",
        "\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
        "    print(f'AUC-ROC: {auc_roc:.4f}')\n",
        "    print(f'Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=tumor_types, yticklabels=tumor_types)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "    return accuracy, precision, recall, f1, auc_roc, avg_loss, all_preds, all_labels\n",
        "\n",
        "def visualize_model_attention(model, input_tensor, target_class):\n",
        "    model.eval()\n",
        "    cam = GradCAM(model=model, target_layers=[model.layer4[-1]], use_cuda=torch.cuda.is_available())\n",
        "    grayscale_cam = cam(input_tensor=input_tensor.unsqueeze(0), target_category=target_class)\n",
        "    visualization = show_cam_on_image(input_tensor.permute(1, 2, 0).numpy(), grayscale_cam[0, :], use_rgb=True)\n",
        "    plt.imshow(visualization)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Grad-CAM for class {target_class}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0DDdlzmlqlXv",
      "metadata": {
        "id": "0DDdlzmlqlXv"
      },
      "outputs": [],
      "source": [
        "def get_model_size(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    size = os.path.getsize(\"temp.p\") / 1e6  # Size in MB\n",
        "    os.remove('temp.p')\n",
        "    return size\n",
        "\n",
        "def create_metrics_dataframe(model, test_acc, precision, recall, f1, auc_roc, train_time, test_loss):\n",
        "    metrics = {\n",
        "        'Metric': ['Overall Accuracy', 'F1 Score', 'Cross Entropy Loss', 'Training Time (s)', 'Number of Parameters', 'Model Size (MB)'],\n",
        "        'Value': [\n",
        "            test_acc,\n",
        "            f1,\n",
        "            test_loss,\n",
        "            train_time,\n",
        "            sum(p.numel() for p in model.parameters()),\n",
        "            get_model_size(model)\n",
        "        ]\n",
        "    }\n",
        "    df = pd.DataFrame(metrics)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "thgX5dh7gc-f",
      "metadata": {
        "id": "thgX5dh7gc-f"
      },
      "outputs": [],
      "source": [
        "# Define the base path in your Google Drive\n",
        "base_path = '/content/drive/MyDrive/Colab Notebooks'\n",
        "\n",
        "# Function to save the model\n",
        "def save_model(model, filename):\n",
        "    save_path = os.path.join(base_path, filename)\n",
        "    try:\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"Model saved successfully to {save_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving model: {e}\")\n",
        "\n",
        "# Function to load the model\n",
        "def load_model(model, filename):\n",
        "    load_path = os.path.join(base_path, filename)\n",
        "    try:\n",
        "        model.load_state_dict(torch.load(load_path))\n",
        "        print(f\"Model loaded successfully from {load_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading model: {e}\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rcyyQz2V1Sbb",
      "metadata": {
        "id": "rcyyQz2V1Sbb"
      },
      "source": [
        "Training Loop: GPU T4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UP_z22M1OqN-",
      "metadata": {
        "collapsed": true,
        "id": "UP_z22M1OqN-"
      },
      "outputs": [],
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Setup\n",
        "    train_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Training'\n",
        "    test_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "    tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "    num_classes = len(tumor_types)\n",
        "\n",
        "    # Data augmentation and normalization for training\n",
        "    # Just normalization for validation/testing\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    # Create the dataset\n",
        "    full_dataset = MRIDataset(train_folder, tumor_types, transform=data_transforms['train'])\n",
        "    test_dataset = MRIDataset(test_folder, tumor_types, transform=data_transforms['val'])\n",
        "    results = []\n",
        "    # K-Fold Cross-validation\n",
        "    k_folds = 5\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold, (train_ids, val_ids) in enumerate(kfold.split(full_dataset)):\n",
        "        print(f'FOLD {fold+1}')\n",
        "        print('--------------------------------')\n",
        "\n",
        "        train_subsampler = SubsetRandomSampler(train_ids)\n",
        "        val_subsampler = SubsetRandomSampler(val_ids)\n",
        "\n",
        "        train_loader = DataLoader(full_dataset, batch_size=32, sampler=train_subsampler)\n",
        "        val_loader = DataLoader(full_dataset, batch_size=32, sampler=val_subsampler)\n",
        "\n",
        "        model = initialize_resnet50_model(num_classes)\n",
        "        model, val_acc, train_time = train_model(model, train_loader, val_loader)\n",
        "\n",
        "        results.append({\n",
        "            'Fold': fold+1,\n",
        "            'Validation Accuracy': val_acc,\n",
        "            'Training Time (s)': train_time\n",
        "        })\n",
        "\n",
        "        # Save the model for this fold\n",
        "        save_model(model, f'model_fold_{fold+1}.pth')\n",
        "\n",
        "    # After k-fold cross-validation, train on the entire training set\n",
        "    print('FINAL TRAINING')\n",
        "    print('--------------------------------')\n",
        "    train_loader = DataLoader(full_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    final_model = initialize_model(num_classes)\n",
        "    final_model, final_val_acc, final_train_time = train_model(final_model, train_loader, val_loader)\n",
        "\n",
        "    results.append({\n",
        "        'Fold': 'Final',\n",
        "        'Validation Accuracy': final_val_acc,\n",
        "        'Training Time (s)': final_train_time\n",
        "    })\n",
        "\n",
        "    # Create and display the summary table\n",
        "    summary_df = pd.DataFrame(results)\n",
        "    print(\"\\nTraining Summary:\")\n",
        "    print(summary_df.to_string(index=False))\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    test_acc, precision, recall, f1, auc_roc, test_loss, _, _ = evaluate_model(final_model, test_loader, tumor_types)\n",
        "\n",
        "    print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Create and display the metrics DataFrame\n",
        "    metrics_df = create_metrics_dataframe(final_model, test_acc, precision, recall, f1, auc_roc, final_train_time, test_loss)\n",
        "    print(\"\\nModel Metrics:\")\n",
        "    print(metrics_df.to_string(index=False))\n",
        "\n",
        "    # Save the DataFrame\n",
        "    metrics_csv_path = os.path.join(base_path, 'resnet50_metrics.csv')\n",
        "    metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "    print(f\"\\nMetrics saved to {metrics_csv_path}\")\n",
        "\n",
        "    # Save the final model\n",
        "    save_model(final_model, 'final_mriresnet50_model.pth')\n",
        "\n",
        "    print(\"Training, evaluation, and metrics logging complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rErMLCWIjJXo",
      "metadata": {
        "id": "rErMLCWIjJXo"
      },
      "source": [
        "## Model 2: ResNet101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "LFjDeloGjJzo",
      "metadata": {
        "id": "LFjDeloGjJzo"
      },
      "outputs": [],
      "source": [
        "def initialize_model_resnet101(num_classes):\n",
        "    model = models.resnet101(pretrained=True)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "    return model\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=100, patience=10):\n",
        "    start_time = time.time()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Initialize criterion, optimizer, and scheduler\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # Separate parameter groups for different learning rates\n",
        "    optimizer = optim.Adam([\n",
        "        {'params': model.fc.parameters(), 'lr': 0.001},\n",
        "        {'params': model.layer4.parameters(), 'lr': 0.0001}\n",
        "    ])\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_acc = 0.0\n",
        "    epochs_no_improve = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping to prevent exploding gradients\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_acc = train_correct / train_total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Save best model\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_val_acc = val_acc\n",
        "            epochs_no_improve = 0\n",
        "            best_model = model.state_dict()\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        # Early stopping check\n",
        "        if epochs_no_improve == patience:\n",
        "            print('Early stopping triggered!')\n",
        "            model.load_state_dict(best_model)\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    print(f'Total training time: {training_time/60:.2f} minutes')\n",
        "\n",
        "    return model, best_val_acc, training_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wqWkFG9hk2PX",
      "metadata": {
        "collapsed": true,
        "id": "wqWkFG9hk2PX"
      },
      "outputs": [],
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Setup\n",
        "    train_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Training'\n",
        "    test_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "    tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "    num_classes = len(tumor_types)\n",
        "\n",
        "    # Data augmentation and normalization for training\n",
        "    # Just normalization for validation/testing\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    # Create the dataset\n",
        "    full_dataset = MRIDataset(train_folder, tumor_types, transform=data_transforms['train'])\n",
        "    test_dataset = MRIDataset(test_folder, tumor_types, transform=data_transforms['val'])\n",
        "    results = []\n",
        "\n",
        "    # K-Fold Cross-validation\n",
        "    k_folds = 5\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold, (train_ids, val_ids) in enumerate(kfold.split(full_dataset)):\n",
        "        print(f'FOLD {fold+1}')\n",
        "        print('--------------------------------')\n",
        "\n",
        "        train_subsampler = SubsetRandomSampler(train_ids)\n",
        "        val_subsampler = SubsetRandomSampler(val_ids)\n",
        "\n",
        "        train_loader = DataLoader(full_dataset, batch_size=32, sampler=train_subsampler)\n",
        "        val_loader = DataLoader(full_dataset, batch_size=32, sampler=val_subsampler)\n",
        "\n",
        "        model = initialize_model_resnet101(num_classes)\n",
        "        model, val_acc, train_time = train_model(model, train_loader, val_loader)\n",
        "\n",
        "        results.append({\n",
        "            'Fold': fold+1,\n",
        "            'Validation Accuracy': val_acc,\n",
        "            'Training Time (s)': train_time\n",
        "        })\n",
        "\n",
        "        # Save the model for this fold\n",
        "        save_model(model, f'resnet101_model_fold_{fold+1}.pth')\n",
        "\n",
        "    # After k-fold cross-validation, train on the entire training set\n",
        "    print('FINAL TRAINING')\n",
        "    print('--------------------------------')\n",
        "    train_loader = DataLoader(full_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    final_model = initialize_model_resnet101(num_classes)\n",
        "    final_model, final_val_acc, final_train_time = train_model(final_model, train_loader, val_loader)\n",
        "\n",
        "    results.append({\n",
        "        'Fold': 'Final',\n",
        "        'Validation Accuracy': final_val_acc,\n",
        "        'Training Time (s)': final_train_time\n",
        "    })\n",
        "\n",
        "    # Create and display the summary table\n",
        "    summary_df = pd.DataFrame(results)\n",
        "    print(\"\\nTraining Summary:\")\n",
        "    print(summary_df.to_string(index=False))\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    test_acc, precision, recall, f1, auc_roc, test_loss, _, _ = evaluate_model(final_model, test_loader, tumor_types)\n",
        "\n",
        "    print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Create and display the metrics DataFrame\n",
        "    metrics_df = create_metrics_dataframe(final_model, test_acc, precision, recall, f1, auc_roc, final_train_time, test_loss)\n",
        "    print(\"\\nModel Metrics:\")\n",
        "    print(metrics_df.to_string(index=False))\n",
        "\n",
        "    # Save the DataFrame\n",
        "    metrics_csv_path = os.path.join(base_path, 'resnet101_metrics.csv')\n",
        "    metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "    print(f\"\\nMetrics saved to {metrics_csv_path}\")\n",
        "\n",
        "    # Save the final model\n",
        "    save_model(final_model, 'final_resnet101_classification_model.pth')\n",
        "\n",
        "    print(\"Training, evaluation, and metrics logging complete!\")\n",
        "\n",
        "def evaluate_model(model, test_loader, tumor_types):\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "    total_loss = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_probs = np.array(all_probs)\n",
        "\n",
        "    accuracy = (all_preds == all_labels).mean()\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "    auc_roc = roc_auc_score(all_labels, all_probs, average='weighted', multi_class='ovr')\n",
        "    avg_loss = total_loss / len(test_loader.dataset)\n",
        "\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
        "    print(f'AUC-ROC: {auc_roc:.4f}')\n",
        "    print(f'Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=tumor_types, yticklabels=tumor_types)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "    return accuracy, precision, recall, f1, auc_roc, avg_loss, all_preds, all_labels\n",
        "\n",
        "def visualize_model_attention(model, input_tensor, target_class):\n",
        "    model.eval()\n",
        "    cam = GradCAM(model=model, target_layers=[model.layer4[-1]], use_cuda=torch.cuda.is_available())\n",
        "    grayscale_cam = cam(input_tensor=input_tensor.unsqueeze(0), target_category=target_class)\n",
        "    visualization = show_cam_on_image(input_tensor.permute(1, 2, 0).numpy(), grayscale_cam[0, :], use_rgb=True)\n",
        "    plt.imshow(visualization)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Grad-CAM for class {target_class}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3u6u02DafgcF",
      "metadata": {
        "id": "3u6u02DafgcF"
      },
      "source": [
        "# EfficientNets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93PrO5bF1pHh",
      "metadata": {
        "id": "93PrO5bF1pHh"
      },
      "source": [
        "## Model 3: EfficientNetB0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tIfH-g2j1pfD",
      "metadata": {
        "id": "tIfH-g2j1pfD"
      },
      "outputs": [],
      "source": [
        "def initialize_efficientnet0_model(num_classes):\n",
        "    model = models.efficientnet_b0(pretrained=True)\n",
        "    num_ftrs = model.classifier[1].in_features\n",
        "    model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JeOu-qn0LZt3",
      "metadata": {
        "id": "JeOu-qn0LZt3"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, num_epochs=100, patience=10):\n",
        "    start_time = time.time()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_acc = 0.0\n",
        "    epochs_no_improve = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_acc = train_correct / train_total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "             best_val_loss = val_loss\n",
        "             best_val_acc = val_acc\n",
        "             epochs_no_improve = 0\n",
        "             best_model = model.state_dict()\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve == patience:\n",
        "            print('Early stopping!')\n",
        "            model.load_state_dict(best_model)\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    return model, best_val_acc, training_time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vN3yqs_dFHiv",
      "metadata": {
        "id": "vN3yqs_dFHiv"
      },
      "outputs": [],
      "source": [
        "def visualize_model_attention(model, input_tensor, target_class):\n",
        "    model.eval()\n",
        "    cam = GradCAM(model=model, target_layers=[model.features[-1]], use_cuda=torch.cuda.is_available())\n",
        "    grayscale_cam = cam(input_tensor=input_tensor.unsqueeze(0), target_category=target_class)\n",
        "    visualization = show_cam_on_image(input_tensor.permute(1, 2, 0).numpy(), grayscale_cam[0, :], use_rgb=True)\n",
        "    plt.imshow(visualization)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Grad-CAM for class {target_class}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vr3mgWHzFgw2",
      "metadata": {
        "collapsed": true,
        "id": "vr3mgWHzFgw2"
      },
      "outputs": [],
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Setup\n",
        "    train_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Training'\n",
        "    test_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "    tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "    num_classes = len(tumor_types)\n",
        "\n",
        "    # Data augmentation and normalization for training\n",
        "    # Just normalization for validation/testing\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    # Create the dataset\n",
        "    full_dataset = MRIDataset(train_folder, tumor_types, transform=data_transforms['train'])\n",
        "    test_dataset = MRIDataset(test_folder, tumor_types, transform=data_transforms['val'])\n",
        "    results = []\n",
        "\n",
        "    # K-Fold Cross-validation\n",
        "    k_folds = 5\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold, (train_ids, val_ids) in enumerate(kfold.split(full_dataset)):\n",
        "        print(f'FOLD {fold+1}')\n",
        "        print('--------------------------------')\n",
        "\n",
        "        train_subsampler = SubsetRandomSampler(train_ids)\n",
        "        val_subsampler = SubsetRandomSampler(val_ids)\n",
        "\n",
        "        train_loader = DataLoader(full_dataset, batch_size=32, sampler=train_subsampler)\n",
        "        val_loader = DataLoader(full_dataset, batch_size=32, sampler=val_subsampler)\n",
        "\n",
        "        model = initialize_efficientnet0_model(num_classes)\n",
        "        model, val_acc, train_time = train_model(model, train_loader, val_loader)\n",
        "\n",
        "        results.append({\n",
        "            'Fold': fold+1,\n",
        "            'Validation Accuracy': val_acc,\n",
        "            'Training Time (s)': train_time\n",
        "        })\n",
        "\n",
        "        # Save the model for this fold\n",
        "        save_model(model, f'efficientnet_b0_model_fold_{fold+1}.pth')\n",
        "\n",
        "    # After k-fold cross-validation, train on the entire training set\n",
        "    print('FINAL TRAINING')\n",
        "    print('--------------------------------')\n",
        "    train_loader = DataLoader(full_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    final_model = initialize_model(num_classes)\n",
        "    final_model, final_val_acc, final_train_time = train_model(final_model, train_loader, val_loader)\n",
        "\n",
        "    results.append({\n",
        "        'Fold': 'Final',\n",
        "        'Validation Accuracy': final_val_acc,\n",
        "        'Training Time (s)': final_train_time\n",
        "    })\n",
        "\n",
        "    # Create and display the summary table\n",
        "    summary_df = pd.DataFrame(results)\n",
        "    print(\"\\nTraining Summary:\")\n",
        "    print(summary_df.to_string(index=False))\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    test_acc, precision, recall, f1, auc_roc, test_loss, _, _ = evaluate_model(final_model, test_loader, tumor_types)\n",
        "\n",
        "    print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Create and display the metrics DataFrame\n",
        "    metrics_df = create_metrics_dataframe(final_model, test_acc, precision, recall, f1, auc_roc, final_train_time, test_loss)\n",
        "    print(\"\\nModel Metrics:\")\n",
        "    print(metrics_df.to_string(index=False))\n",
        "\n",
        "    # Save the DataFrame\n",
        "    metrics_csv_path = os.path.join(base_path, 'efficientnet_b0_model_metrics.csv')\n",
        "    metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "    print(f\"\\nMetrics saved to {metrics_csv_path}\")\n",
        "\n",
        "    # Save the final model\n",
        "    save_model(final_model, 'final_efficientnet_b0_mri_classification_model.pth')\n",
        "\n",
        "    print(\"Training, evaluation, and metrics logging complete for EfficientNet-B0 model!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7sFe-Abw2Ft4",
      "metadata": {
        "id": "7sFe-Abw2Ft4"
      },
      "source": [
        "##Remark:\n",
        "EfficienNet and ResNet are both CNNs that specialize in edge detection by nature. So it is normal to observe that model attention goes to the edge of tumours instead of directly hovering above it."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H3xSWa50m-QU",
      "metadata": {
        "id": "H3xSWa50m-QU"
      },
      "source": [
        "## Model 4: EfficientNetB1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4oNewZxGnArz",
      "metadata": {
        "id": "4oNewZxGnArz"
      },
      "outputs": [],
      "source": [
        "def initialize_efficientnetb1_model(num_classes):\n",
        "    model = models.efficientnet_b1(pretrained=True)\n",
        "    num_ftrs = model.classifier[1].in_features\n",
        "    model.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
        "    return model\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=100, patience=10):\n",
        "    start_time = time.time()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_acc = 0.0\n",
        "    epochs_no_improve = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_acc = train_correct / train_total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "             best_val_loss = val_loss\n",
        "             best_val_acc = val_acc\n",
        "             epochs_no_improve = 0\n",
        "             best_model = model.state_dict()\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve == patience:\n",
        "            print('Early stopping!')\n",
        "            model.load_state_dict(best_model)\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    return model, best_val_acc, training_time\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HSr4W0WpnAvZ",
      "metadata": {
        "collapsed": true,
        "id": "HSr4W0WpnAvZ"
      },
      "outputs": [],
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Setup\n",
        "    train_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Training'\n",
        "    test_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "    tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "    num_classes = len(tumor_types)\n",
        "\n",
        "    # Data augmentation and normalization for training\n",
        "    # Just normalization for validation/testing\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    # Create the dataset\n",
        "    full_dataset = MRIDataset(train_folder, tumor_types, transform=data_transforms['train'])\n",
        "    test_dataset = MRIDataset(test_folder, tumor_types, transform=data_transforms['val'])\n",
        "    results = []\n",
        "\n",
        "    # K-Fold Cross-validation\n",
        "    k_folds = 5\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold, (train_ids, val_ids) in enumerate(kfold.split(full_dataset)):\n",
        "        print(f'FOLD {fold+1}')\n",
        "        print('--------------------------------')\n",
        "\n",
        "        train_subsampler = SubsetRandomSampler(train_ids)\n",
        "        val_subsampler = SubsetRandomSampler(val_ids)\n",
        "\n",
        "        train_loader = DataLoader(full_dataset, batch_size=32, sampler=train_subsampler)\n",
        "        val_loader = DataLoader(full_dataset, batch_size=32, sampler=val_subsampler)\n",
        "\n",
        "        model = initialize_model(num_classes)\n",
        "        model, val_acc, train_time = train_model(model, train_loader, val_loader)\n",
        "\n",
        "        results.append({\n",
        "            'Fold': fold+1,\n",
        "            'Validation Accuracy': val_acc,\n",
        "            'Training Time (s)': train_time\n",
        "        })\n",
        "\n",
        "        # Save the model for this fold\n",
        "        save_model(model, f'efficientnet_b1_model_fold_{fold+1}.pth')\n",
        "\n",
        "    # After k-fold cross-validation, train on the entire training set\n",
        "    print('FINAL TRAINING')\n",
        "    print('--------------------------------')\n",
        "    train_loader = DataLoader(full_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    final_model = initialize_efficientnetb1_model(num_classes)\n",
        "    final_model, final_val_acc, final_train_time = train_model(final_model, train_loader, val_loader)\n",
        "\n",
        "    results.append({\n",
        "        'Fold': 'Final',\n",
        "        'Validation Accuracy': final_val_acc,\n",
        "        'Training Time (s)': final_train_time\n",
        "    })\n",
        "\n",
        "    # Create and display the summary table\n",
        "    summary_df = pd.DataFrame(results)\n",
        "    print(\"\\nTraining Summary:\")\n",
        "    print(summary_df.to_string(index=False))\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    test_acc, precision, recall, f1, auc_roc, test_loss, _, _ = evaluate_model(final_model, test_loader, tumor_types)\n",
        "\n",
        "    print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Create and display the metrics DataFrame\n",
        "    metrics_df = create_metrics_dataframe(final_model, test_acc, precision, recall, f1, auc_roc, final_train_time, test_loss)\n",
        "    print(\"\\nModel Metrics:\")\n",
        "    print(metrics_df.to_string(index=False))\n",
        "\n",
        "    # Save the DataFrame\n",
        "    metrics_csv_path = os.path.join(base_path, 'efficientnet_b1_model_metrics.csv')\n",
        "    metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "    print(f\"\\nMetrics saved to {metrics_csv_path}\")\n",
        "\n",
        "    # Save the final model\n",
        "    save_model(final_model, 'final_efficientnet_b1_mri_classification_model.pth')\n",
        "\n",
        "    print(\"Training, evaluation, and metrics logging complete for EfficientNet-B1 model!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Bz3uQtXzrTOR",
      "metadata": {
        "id": "Bz3uQtXzrTOR"
      },
      "source": [
        "# ViT: Vision transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WzlzElfhfrpo",
      "metadata": {
        "id": "WzlzElfhfrpo"
      },
      "source": [
        "# Model 5: ViT Small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_Ccm2YvvGSPw",
      "metadata": {
        "id": "_Ccm2YvvGSPw"
      },
      "outputs": [],
      "source": [
        "def initialize_vit_model(num_classes):\n",
        "    # Initialize ViT small model from timm\n",
        "    model = timm.create_model('vit_small_patch16_224', pretrained=True)\n",
        "    # Modify the head to match our number of classes\n",
        "    model.head = nn.Linear(model.head.in_features, num_classes)\n",
        "    return model\n",
        "\n",
        "def train_model(model, train_loader, val_loader, num_epochs=100, patience=10):\n",
        "    start_time = time.time()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    # Adjusted learning rate for ViT\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.05)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_val_acc = 0.0\n",
        "    epochs_no_improve = 0\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            train_total += labels.size(0)\n",
        "            train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        train_acc = train_correct / train_total\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                val_total += labels.size(0)\n",
        "                val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'Train Loss: {train_loss:.4f} Acc: {train_acc:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_val_acc = val_acc\n",
        "            epochs_no_improve = 0\n",
        "            best_model = model.state_dict()\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve == patience:\n",
        "            print('Early stopping!')\n",
        "            model.load_state_dict(best_model)\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    training_time = end_time - start_time\n",
        "    return model, best_val_acc, training_time\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8LQRGsxrGSTz",
      "metadata": {
        "collapsed": true,
        "id": "8LQRGsxrGSTz"
      },
      "outputs": [],
      "source": [
        "# Main execution\n",
        "if __name__ == \"__main__\":\n",
        "    # Setup\n",
        "    train_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Training'\n",
        "    test_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "    tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "    num_classes = len(tumor_types)\n",
        "\n",
        "    # Data augmentation and normalization for training\n",
        "    # Using ViT-specific preprocessing\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # ViT standard normalization\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    # Rest of the code remains the same, just update the model names in save operations\n",
        "    full_dataset = MRIDataset(train_folder, tumor_types, transform=data_transforms['train'])\n",
        "    test_dataset = MRIDataset(test_folder, tumor_types, transform=data_transforms['val'])\n",
        "    results = []\n",
        "\n",
        "    # K-Fold Cross-validation\n",
        "    k_folds = 5\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold, (train_ids, val_ids) in enumerate(kfold.split(full_dataset)):\n",
        "        print(f'FOLD {fold+1}')\n",
        "        print('--------------------------------')\n",
        "\n",
        "        train_subsampler = SubsetRandomSampler(train_ids)\n",
        "        val_subsampler = SubsetRandomSampler(val_ids)\n",
        "\n",
        "        train_loader = DataLoader(full_dataset, batch_size=32, sampler=train_subsampler)\n",
        "        val_loader = DataLoader(full_dataset, batch_size=32, sampler=val_subsampler)\n",
        "\n",
        "        model = initialize_model(num_classes)\n",
        "        model, val_acc, train_time = train_model(model, train_loader, val_loader)\n",
        "\n",
        "        results.append({\n",
        "            'Fold': fold+1,\n",
        "            'Validation Accuracy': val_acc,\n",
        "            'Training Time (s)': train_time\n",
        "        })\n",
        "\n",
        "        # Save the model for this fold\n",
        "        save_model(model, f'vit_small_model_fold_{fold+1}.pth')\n",
        "\n",
        "    # Final training on entire dataset\n",
        "    print('FINAL TRAINING')\n",
        "    print('--------------------------------')\n",
        "    train_loader = DataLoader(full_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    final_model = initialize_model(num_classes)\n",
        "    final_model, final_val_acc, final_train_time = train_model(final_model, train_loader, val_loader)\n",
        "\n",
        "    results.append({\n",
        "        'Fold': 'Final',\n",
        "        'Validation Accuracy': final_val_acc,\n",
        "        'Training Time (s)': final_train_time\n",
        "    })\n",
        "\n",
        "    # Create and display the summary table\n",
        "    summary_df = pd.DataFrame(results)\n",
        "    print(\"\\nTraining Summary:\")\n",
        "    print(summary_df.to_string(index=False))\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "    test_acc, precision, recall, f1, auc_roc, test_loss, _, _ = evaluate_model(final_model, test_loader, tumor_types)\n",
        "\n",
        "    print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # Create and display the metrics DataFrame\n",
        "    metrics_df = create_metrics_dataframe(final_model, test_acc, precision, recall, f1, auc_roc, final_train_time, test_loss)\n",
        "    print(\"\\nModel Metrics:\")\n",
        "    print(metrics_df.to_string(index=False))\n",
        "\n",
        "    # Save the metrics\n",
        "    metrics_csv_path = os.path.join(base_path, 'vit_small_model_metrics.csv')\n",
        "    metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "    print(f\"\\nMetrics saved to {metrics_csv_path}\")\n",
        "\n",
        "    # Save the final model\n",
        "    save_model(final_model, 'final_vit_small_mri_classification_model.pth')\n",
        "\n",
        "    print(\"Training, evaluation, and metrics logging complete for ViT Small model!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2BXG1qief1Fx",
      "metadata": {
        "id": "2BXG1qief1Fx"
      },
      "source": [
        "# LeVits"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZqxUGTdOWIIV",
      "metadata": {
        "id": "ZqxUGTdOWIIV"
      },
      "source": [
        "## Model 6: Levit-256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N1VhX8IwcVog",
      "metadata": {
        "id": "N1VhX8IwcVog"
      },
      "outputs": [],
      "source": [
        "class LeViT256Model(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super(LeViT256Model, self).__init__()\n",
        "\n",
        "        # Load pretrained LeViT-256 model\n",
        "        self.levit = timm.create_model('levit_256', pretrained=pretrained, num_classes=0)\n",
        "\n",
        "        # Get the number of features from LeViT\n",
        "        levit_num_features = self.levit.num_features\n",
        "\n",
        "        # Add final classification layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(levit_num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Process input through LeViT\n",
        "        features = self.levit(x)\n",
        "\n",
        "        # Final classification\n",
        "        output = self.fc(features)\n",
        "        return output\n",
        "\n",
        "# Function to initialize the model\n",
        "def initialize_levit256_model(num_classes, pretrained=True):\n",
        "    return LeViT256Model(num_classes, pretrained)\n",
        "\n",
        "# Evaluation Function\n",
        "def evaluate_model(model, test_loader, tumor_types):\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "    total_loss = 0.0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_loss += loss.item() * inputs.size(0)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(torch.nn.functional.softmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_probs = np.array(all_probs)\n",
        "\n",
        "    accuracy = (all_preds == all_labels).mean()\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n",
        "    auc_roc = roc_auc_score(all_labels, all_probs, average='weighted', multi_class='ovr')\n",
        "    avg_loss = total_loss / len(test_loader.dataset)\n",
        "\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "    print(f'Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}')\n",
        "    print(f'AUC-ROC: {auc_roc:.4f}')\n",
        "    print(f'Average Loss: {avg_loss:.4f}')\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=tumor_types, yticklabels=tumor_types)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.show()\n",
        "\n",
        "    return accuracy, precision, recall, f1, auc_roc, avg_loss, all_preds, all_labels\n",
        "\n",
        "# Function to create metrics DataFrame\n",
        "def create_metrics_dataframe(model, test_acc, precision, recall, f1, auc_roc, train_time, test_loss):\n",
        "    metrics = {\n",
        "        'Metric': ['Overall Accuracy', 'F1 Score', 'Cross Entropy Loss', 'Training Time (s)', 'Number of Parameters', 'Model Size (MB)'],\n",
        "        'Value': [\n",
        "            test_acc,\n",
        "            f1,\n",
        "            test_loss,\n",
        "            train_time,\n",
        "            sum(p.numel() for p in model.parameters()),\n",
        "            sum(p.nelement() * p.element_size() for p in model.parameters()) / (1024 * 1024)\n",
        "        ]\n",
        "    }\n",
        "    df = pd.DataFrame(metrics)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Qbwe9hchh0rU",
      "metadata": {
        "id": "Qbwe9hchh0rU"
      },
      "outputs": [],
      "source": [
        "def train_levit_model(train_dataset, test_dataset, num_classes, num_epochs=100, patience=10, k_folds=5):\n",
        "    results = []\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # K-Fold Cross-validation\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold, (train_ids, val_ids) in enumerate(kfold.split(train_dataset)):\n",
        "        print(f'FOLD {fold+1}')\n",
        "        print('--------------------------------')\n",
        "\n",
        "        train_subsampler = SubsetRandomSampler(train_ids)\n",
        "        val_subsampler = SubsetRandomSampler(val_ids)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_subsampler, num_workers=2, pin_memory=True)\n",
        "        val_loader = DataLoader(train_dataset, batch_size=32, sampler=val_subsampler, num_workers=2, pin_memory=True)\n",
        "\n",
        "        model = initialize_levit_model(num_classes).to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        best_model = None\n",
        "        epochs_no_improve = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Training phase\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "\n",
        "            for inputs, labels in train_loader:\n",
        "                try:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    train_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    train_total += labels.size(0)\n",
        "                    train_correct += (predicted == labels).sum().item()\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"RuntimeError in training loop: {e}\")\n",
        "                    print(f\"Input shape: {inputs.shape}\")\n",
        "                    continue\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    try:\n",
        "                        inputs, labels = inputs.to(device), labels.to(device)\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        val_loss += loss.item() * inputs.size(0)\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "                        val_total += labels.size(0)\n",
        "                        val_correct += (predicted == labels).sum().item()\n",
        "                    except RuntimeError as e:\n",
        "                        print(f\"RuntimeError in validation loop: {e}\")\n",
        "                        print(f\"Input shape: {inputs.shape}\")\n",
        "                        continue\n",
        "\n",
        "            # Calculate average losses and accuracies\n",
        "            train_loss = train_loss / len(train_loader.dataset)\n",
        "            val_loss = val_loss / len(val_loader.dataset)\n",
        "            train_acc = train_correct / train_total\n",
        "            val_acc = val_correct / val_total\n",
        "\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            # Save the first model state or if we have a new best validation loss\n",
        "            if best_model is None or val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = model.state_dict()\n",
        "                epochs_no_improve = 0\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "\n",
        "            if epochs_no_improve == patience:\n",
        "                print('Early stopping!')\n",
        "                break\n",
        "\n",
        "        end_time = time.time()\n",
        "        training_time = end_time - start_time\n",
        "        results.append({\n",
        "            'Fold': fold+1,\n",
        "            'Best Validation Loss': best_val_loss,\n",
        "            'Training Time (s)': training_time\n",
        "        })\n",
        "\n",
        "    # Final training on entire dataset\n",
        "    print('FINAL TRAINING')\n",
        "    print('--------------------------------')\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    final_model = initialize_levit_model(num_classes).to(device)\n",
        "    optimizer = optim.Adam(final_model.parameters(), lr=0.001)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model = None  # Initialize best_model\n",
        "    epochs_no_improve = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        final_model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            try:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = final_model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                train_total += labels.size(0)\n",
        "                train_correct += (predicted == labels).sum().item()\n",
        "            except RuntimeError as e:\n",
        "                print(f\"RuntimeError in final training loop: {e}\")\n",
        "                print(f\"Input shape: {inputs.shape}\")\n",
        "                continue\n",
        "\n",
        "        # Validation phase\n",
        "        final_model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                try:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = final_model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    val_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"RuntimeError in final validation loop: {e}\")\n",
        "                    print(f\"Input shape: {inputs.shape}\")\n",
        "                    continue\n",
        "\n",
        "        # Calculate average losses and accuracies\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        val_loss = val_loss / len(test_loader.dataset)\n",
        "        train_acc = train_correct / train_total\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Save the first model state or if we have a new best validation loss\n",
        "        if best_model is None or val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model = final_model.state_dict()\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve == patience:\n",
        "            print('Early stopping!')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    final_training_time = end_time - start_time\n",
        "    results.append({\n",
        "        'Fold': 'Final',\n",
        "        'Best Validation Loss': best_val_loss,\n",
        "        'Training Time (s)': final_training_time\n",
        "    })\n",
        "\n",
        "    # Load the best model state\n",
        "    final_model.load_state_dict(best_model)\n",
        "\n",
        "    # Save the final model\n",
        "    torch.save({\n",
        "        'epoch': len(results),\n",
        "        'model_state_dict': best_model,\n",
        "        'results': results\n",
        "    }, 'final_levit_256_model.pth')\n",
        "\n",
        "    return results, final_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cMtGcId4hbH_",
      "metadata": {
        "collapsed": true,
        "id": "cMtGcId4hbH_"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Disable torch compile to avoid dynamo issues\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Setup\n",
        "    base_path = '/content/drive/MyDrive/Colab Notebooks'\n",
        "    train_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Training'\n",
        "    test_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "    tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "    num_classes = len(tumor_types)\n",
        "\n",
        "    # Create checkpoint directory\n",
        "    checkpoint_dir = os.path.join(base_path, 'checkpoints')\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Data augmentation and normalization for training\n",
        "    # Just normalization for validation/testing\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Create the datasets\n",
        "        train_dataset = MRIDataset(train_folder, tumor_types, transform=data_transforms['train'])\n",
        "        test_dataset = MRIDataset(test_folder, tumor_types, transform=data_transforms['val'])\n",
        "\n",
        "        # Print dataset sizes\n",
        "        print(\"Dataset sizes:\")\n",
        "        print(f\"Training: {len(train_dataset)}\")\n",
        "        print(f\"Testing: {len(test_dataset)}\")\n",
        "\n",
        "        # Train the LeViT-256 model\n",
        "        results, final_model = train_levit_model(train_dataset, test_dataset, num_classes)\n",
        "\n",
        "        # Display training results\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(\"\\nTraining Results:\")\n",
        "        print(results_df)\n",
        "\n",
        "        # Save training history\n",
        "        history_path = os.path.join(base_path, 'levit_256_training_history.csv')\n",
        "        results_df.to_csv(history_path, index=False)\n",
        "        print(f\"Training history saved to {history_path}\")\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
        "        test_acc, precision, recall, f1, auc_roc, test_loss, predictions, true_labels = evaluate_model(\n",
        "            final_model,\n",
        "            test_loader,\n",
        "            tumor_types\n",
        "        )\n",
        "\n",
        "        # Create and display the metrics DataFrame\n",
        "        metrics_df = create_metrics_dataframe(\n",
        "            final_model,\n",
        "            test_acc,\n",
        "            precision,\n",
        "            recall,\n",
        "            f1,\n",
        "            auc_roc,\n",
        "            results[-1]['Training Time (s)'],\n",
        "            test_loss\n",
        "        )\n",
        "        print(\"\\nModel Metrics:\")\n",
        "        print(metrics_df.to_string(index=False))\n",
        "\n",
        "        # Save the metrics DataFrame\n",
        "        metrics_csv_path = os.path.join(base_path, 'levit_256_model_metrics.csv')\n",
        "        metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "        print(f\"\\nMetrics saved to {metrics_csv_path}\")\n",
        "\n",
        "        # Save the final model with all relevant information\n",
        "        model_path = os.path.join(base_path, 'levit_256_model_final.pth')\n",
        "        torch.save({\n",
        "            'epoch': len(results),\n",
        "            'model_state_dict': final_model.state_dict(),\n",
        "            'results': results,\n",
        "            'test_metrics': {\n",
        "                'accuracy': test_acc,\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1': f1,\n",
        "                'auc_roc': auc_roc,\n",
        "                'test_loss': test_loss\n",
        "            }\n",
        "        }, model_path)\n",
        "        print(f\"\\nModel saved to {model_path}\")\n",
        "\n",
        "        # Save predictions\n",
        "        predictions_df = pd.DataFrame({\n",
        "            'True_Label': [tumor_types[i] for i in true_labels],\n",
        "            'Predicted_Label': [tumor_types[i] for i in predictions]\n",
        "        })\n",
        "        predictions_path = os.path.join(base_path, 'levit_256_test_predictions.csv')\n",
        "        predictions_df.to_csv(predictions_path, index=False)\n",
        "        print(f\"Test predictions saved to {predictions_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        traceback.print_exc()  # This will print the full error traceback\n",
        "        raise e\n",
        "\n",
        "    print(\"\\nLeViT-256 training, evaluation, and metrics logging complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gKu7OREGTT56",
      "metadata": {
        "id": "gKu7OREGTT56"
      },
      "source": [
        "## Model 7: Levit-384"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Xt4KntDS0lWz",
      "metadata": {
        "id": "Xt4KntDS0lWz"
      },
      "outputs": [],
      "source": [
        "class LeViT384Model(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super(LeViT384Model, self).__init__()\n",
        "\n",
        "        # Load pretrained LeViT-384 model\n",
        "        self.levit = timm.create_model('levit_384', pretrained=pretrained, num_classes=0)\n",
        "\n",
        "        # Get the number of features from LeViT\n",
        "        levit_num_features = self.levit.num_features\n",
        "\n",
        "        # Add final classification layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(levit_num_features, 1024),  # Increased intermediate layer size for LeViT-384\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Process input through LeViT\n",
        "        features = self.levit(x)\n",
        "\n",
        "        # Final classification\n",
        "        output = self.fc(features)\n",
        "        return output\n",
        "\n",
        "# Function to initialize the model\n",
        "def initialize_levit384_model(num_classes, pretrained=True):\n",
        "    return LeViT384Model(num_classes, pretrained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YE2GXpUrcVtm",
      "metadata": {
        "collapsed": true,
        "id": "YE2GXpUrcVtm"
      },
      "outputs": [],
      "source": [
        "def train_levit_model(train_dataset, test_dataset, num_classes, num_epochs=100, patience=10, k_folds=5):\n",
        "    results = []\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # K-Fold Cross-validation\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold, (train_ids, val_ids) in enumerate(kfold.split(train_dataset)):\n",
        "        print(f'FOLD {fold+1}')\n",
        "        print('--------------------------------')\n",
        "\n",
        "        train_subsampler = SubsetRandomSampler(train_ids)\n",
        "        val_subsampler = SubsetRandomSampler(val_ids)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_subsampler, num_workers=2, pin_memory=True)\n",
        "        val_loader = DataLoader(train_dataset, batch_size=32, sampler=val_subsampler, num_workers=2, pin_memory=True)\n",
        "\n",
        "        model = initialize_levit_model(num_classes).to(device)\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        best_model = None\n",
        "        epochs_no_improve = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Training phase\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "\n",
        "            for inputs, labels in train_loader:\n",
        "                try:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                    train_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    train_total += labels.size(0)\n",
        "                    train_correct += (predicted == labels).sum().item()\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"RuntimeError in training loop: {e}\")\n",
        "                    print(f\"Input shape: {inputs.shape}\")\n",
        "                    continue\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    try:\n",
        "                        inputs, labels = inputs.to(device), labels.to(device)\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        val_loss += loss.item() * inputs.size(0)\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "                        val_total += labels.size(0)\n",
        "                        val_correct += (predicted == labels).sum().item()\n",
        "                    except RuntimeError as e:\n",
        "                        print(f\"RuntimeError in validation loop: {e}\")\n",
        "                        print(f\"Input shape: {inputs.shape}\")\n",
        "                        continue\n",
        "\n",
        "            # Calculate average losses and accuracies\n",
        "            train_loss = train_loss / len(train_loader.dataset)\n",
        "            val_loss = val_loss / len(val_loader.dataset)\n",
        "            train_acc = train_correct / train_total\n",
        "            val_acc = val_correct / val_total\n",
        "\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            # Save the first model state or if we have a new best validation loss\n",
        "            if best_model is None or val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = model.state_dict()\n",
        "                epochs_no_improve = 0\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "\n",
        "            if epochs_no_improve == patience:\n",
        "                print('Early stopping!')\n",
        "                break\n",
        "\n",
        "        end_time = time.time()\n",
        "        training_time = end_time - start_time\n",
        "        results.append({\n",
        "            'Fold': fold+1,\n",
        "            'Best Validation Loss': best_val_loss,\n",
        "            'Training Time (s)': training_time\n",
        "        })\n",
        "\n",
        "    # Final training on entire dataset\n",
        "    print('FINAL TRAINING')\n",
        "    print('--------------------------------')\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    final_model = initialize_levit_model(num_classes).to(device)\n",
        "    optimizer = optim.Adam(final_model.parameters(), lr=0.001)\n",
        "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model = None  # Initialize best_model\n",
        "    epochs_no_improve = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        final_model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            try:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = final_model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                train_total += labels.size(0)\n",
        "                train_correct += (predicted == labels).sum().item()\n",
        "            except RuntimeError as e:\n",
        "                print(f\"RuntimeError in final training loop: {e}\")\n",
        "                print(f\"Input shape: {inputs.shape}\")\n",
        "                continue\n",
        "\n",
        "        # Validation phase\n",
        "        final_model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                try:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    outputs = final_model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    val_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    val_total += labels.size(0)\n",
        "                    val_correct += (predicted == labels).sum().item()\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"RuntimeError in final validation loop: {e}\")\n",
        "                    print(f\"Input shape: {inputs.shape}\")\n",
        "                    continue\n",
        "\n",
        "        # Calculate average losses and accuracies\n",
        "        train_loss = train_loss / len(train_loader.dataset)\n",
        "        val_loss = val_loss / len(test_loader.dataset)\n",
        "        train_acc = train_correct / train_total\n",
        "        val_acc = val_correct / val_total\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Save the first model state or if we have a new best validation loss\n",
        "        if best_model is None or val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model = final_model.state_dict()\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve == patience:\n",
        "            print('Early stopping!')\n",
        "            break\n",
        "\n",
        "    end_time = time.time()\n",
        "    final_training_time = end_time - start_time\n",
        "    results.append({\n",
        "        'Fold': 'Final',\n",
        "        'Best Validation Loss': best_val_loss,\n",
        "        'Training Time (s)': final_training_time\n",
        "    })\n",
        "\n",
        "    # Load the best model state\n",
        "    final_model.load_state_dict(best_model)\n",
        "\n",
        "    # Save the final model\n",
        "    torch.save({\n",
        "        'epoch': len(results),\n",
        "        'model_state_dict': best_model,\n",
        "        'results': results\n",
        "    }, 'final_levit_384_model.pth')\n",
        "\n",
        "    return results, final_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89n6xoKscVwG",
      "metadata": {
        "collapsed": true,
        "id": "89n6xoKscVwG"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Disable torch compile to avoid dynamo issues\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Setup\n",
        "    base_path = '/content/drive/MyDrive/Colab Notebooks'\n",
        "    train_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Training'\n",
        "    test_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "    tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "    num_classes = len(tumor_types)\n",
        "\n",
        "    # Create checkpoint directory\n",
        "    checkpoint_dir = os.path.join(base_path, 'checkpoints')\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Data augmentation and normalization for training\n",
        "    # Just normalization for validation/testing\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Create the datasets\n",
        "        train_dataset = MRIDataset(train_folder, tumor_types, transform=data_transforms['train'])\n",
        "        test_dataset = MRIDataset(test_folder, tumor_types, transform=data_transforms['val'])\n",
        "\n",
        "        # Print dataset sizes\n",
        "        print(\"Dataset sizes:\")\n",
        "        print(f\"Training: {len(train_dataset)}\")\n",
        "        print(f\"Testing: {len(test_dataset)}\")\n",
        "\n",
        "        # Train the LeViT-384 model\n",
        "        results, final_model = train_levit_model(train_dataset, test_dataset, num_classes)\n",
        "\n",
        "        # Display training results\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(\"\\nTraining Results:\")\n",
        "        print(results_df)\n",
        "\n",
        "        # Save training history\n",
        "        history_path = os.path.join(base_path, 'levit_384_training_history.csv')  # Changed filename\n",
        "        results_df.to_csv(history_path, index=False)\n",
        "        print(f\"Training history saved to {history_path}\")\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        # Reduced batch size for LeViT-384 due to higher memory requirements\n",
        "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)  # Reduced batch size\n",
        "        test_acc, precision, recall, f1, auc_roc, test_loss, predictions, true_labels = evaluate_model(\n",
        "            final_model,\n",
        "            test_loader,\n",
        "            tumor_types\n",
        "        )\n",
        "\n",
        "        # Create and display the metrics DataFrame\n",
        "        metrics_df = create_metrics_dataframe(\n",
        "            final_model,\n",
        "            test_acc,\n",
        "            precision,\n",
        "            recall,\n",
        "            f1,\n",
        "            auc_roc,\n",
        "            results[-1]['Training Time (s)'],\n",
        "            test_loss\n",
        "        )\n",
        "        print(\"\\nModel Metrics:\")\n",
        "        print(metrics_df.to_string(index=False))\n",
        "\n",
        "        # Save the metrics DataFrame\n",
        "        metrics_csv_path = os.path.join(base_path, 'levit_384_model_metrics.csv')  # Changed filename\n",
        "        metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "        print(f\"\\nMetrics saved to {metrics_csv_path}\")\n",
        "\n",
        "        # Save the final model with all relevant information\n",
        "        model_path = os.path.join(base_path, 'levit_384_model_final.pth')  # Changed filename\n",
        "        torch.save({\n",
        "            'epoch': len(results),\n",
        "            'model_state_dict': final_model.state_dict(),\n",
        "            'results': results,\n",
        "            'test_metrics': {\n",
        "                'accuracy': test_acc,\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1': f1,\n",
        "                'auc_roc': auc_roc,\n",
        "                'test_loss': test_loss\n",
        "            }\n",
        "        }, model_path)\n",
        "        print(f\"\\nModel saved to {model_path}\")\n",
        "\n",
        "        # Save predictions\n",
        "        predictions_df = pd.DataFrame({\n",
        "            'True_Label': [tumor_types[i] for i in true_labels],\n",
        "            'Predicted_Label': [tumor_types[i] for i in predictions]\n",
        "        })\n",
        "        predictions_path = os.path.join(base_path, 'levit_384_test_predictions.csv')  # Changed filename\n",
        "        predictions_df.to_csv(predictions_path, index=False)\n",
        "        print(f\"Test predictions saved to {predictions_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        traceback.print_exc()  # This will print the full error traceback\n",
        "        raise e\n",
        "\n",
        "    print(\"\\nLeViT-384 training, evaluation, and metrics logging complete!\")  # Updated message"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pUr2dDUgk8nJ",
      "metadata": {
        "id": "pUr2dDUgk8nJ"
      },
      "source": [
        "# CoAtNets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6IG7TOH-KlTj",
      "metadata": {
        "id": "6IG7TOH-KlTj"
      },
      "source": [
        "## Model 8: CoAtNet-0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i9ixpJCxUSYK",
      "metadata": {
        "id": "i9ixpJCxUSYK"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "\n",
        "class CoAtNet0Model(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CoAtNet0Model, self).__init__()\n",
        "\n",
        "        # Load pre-trained CoAtNet-0-RW model\n",
        "        self.coatnet = timm.create_model('coatnet_0_rw_224', pretrained=True, num_classes=0)\n",
        "\n",
        "        # Enable gradient checkpointing if available\n",
        "        if hasattr(self.coatnet, 'set_grad_checkpointing'):\n",
        "            self.coatnet.set_grad_checkpointing(enable=True)\n",
        "\n",
        "        # Get the number of features from CoAtNet\n",
        "        coatnet_num_features = self.coatnet.num_features\n",
        "\n",
        "        # Add final classification layers with reduced size for memory efficiency\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(coatnet_num_features, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.coatnet(x)\n",
        "        output = self.fc(features)\n",
        "        return output\n",
        "\n",
        "def initialize_coatnet_model(num_classes):\n",
        "    return CoAtNet0Model(num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CXJDXD-qQWnu",
      "metadata": {
        "id": "CXJDXD-qQWnu"
      },
      "outputs": [],
      "source": [
        "def train_coatnet_model(train_dataset, test_dataset, num_classes, num_epochs=50, patience=5, k_folds=5):\n",
        "    results = []\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    print(\"Training with pre-trained weights\")\n",
        "\n",
        "    # Set memory-efficient settings\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "    # Initialize gradient scaler for mixed precision\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Slightly larger batch size since we're fine-tuning\n",
        "    batch_size = 24\n",
        "\n",
        "    # K-Fold Cross-validation\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold, (train_ids, val_ids) in enumerate(kfold.split(train_dataset)):\n",
        "        print(f'FOLD {fold+1}')\n",
        "        print('--------------------------------')\n",
        "\n",
        "        train_subsampler = SubsetRandomSampler(train_ids)\n",
        "        val_subsampler = SubsetRandomSampler(val_ids)\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=train_subsampler,\n",
        "            num_workers=2,\n",
        "            pin_memory=True\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=val_subsampler,\n",
        "            num_workers=2,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        model = initialize_coatnet_model(num_classes).to(device)\n",
        "\n",
        "        # Use different learning rates for pre-trained layers and new layers\n",
        "        optimizer = optim.AdamW([\n",
        "            {'params': model.coatnet.parameters(), 'lr': 1e-5},  # Lower learning rate for pre-trained layers\n",
        "            {'params': model.fc.parameters(), 'lr': 1e-4}       # Higher learning rate for new layers\n",
        "        ])\n",
        "\n",
        "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        best_model = None\n",
        "        epochs_no_improve = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Training phase\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "\n",
        "            for inputs, labels in train_loader:\n",
        "                try:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # Use mixed precision training\n",
        "                    with autocast():\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Scale gradients and optimize\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "\n",
        "                    train_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    train_total += labels.size(0)\n",
        "                    train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    # Clear cache periodically\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"RuntimeError in training loop: {e}\")\n",
        "                    print(f\"Input shape: {inputs.shape}\")\n",
        "                    continue\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    try:\n",
        "                        inputs, labels = inputs.to(device), labels.to(device)\n",
        "                        with autocast():\n",
        "                            outputs = model(inputs)\n",
        "                            loss = criterion(outputs, labels)\n",
        "                        val_loss += loss.item() * inputs.size(0)\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "                        val_total += labels.size(0)\n",
        "                        val_correct += (predicted == labels).sum().item()\n",
        "                    except RuntimeError as e:\n",
        "                        print(f\"RuntimeError in validation loop: {e}\")\n",
        "                        print(f\"Input shape: {inputs.shape}\")\n",
        "                        continue\n",
        "\n",
        "            # Calculate average losses and accuracies\n",
        "            train_loss = train_loss / len(train_loader.dataset)\n",
        "            val_loss = val_loss / len(val_loader.dataset)\n",
        "            train_acc = train_correct / train_total\n",
        "            val_acc = val_correct / val_total\n",
        "\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = model.state_dict()\n",
        "                epochs_no_improve = 0\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "\n",
        "            if epochs_no_improve == patience:\n",
        "                print('Early stopping!')\n",
        "                break\n",
        "\n",
        "            # Clear cache after each epoch\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        end_time = time.time()\n",
        "        training_time = end_time - start_time\n",
        "        results.append({\n",
        "            'Fold': fold+1,\n",
        "            'Best Validation Loss': best_val_loss,\n",
        "            'Training Time (s)': training_time\n",
        "        })\n",
        "\n",
        "    # Save the final model\n",
        "    torch.save({\n",
        "        'epoch': len(results),\n",
        "        'model_state_dict': best_model,\n",
        "        'results': results\n",
        "    }, 'final_pretrained_coatnet_0_model.pth')\n",
        "\n",
        "    return results, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ysXYjXCUSdL",
      "metadata": {
        "collapsed": true,
        "id": "8ysXYjXCUSdL"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Setup\n",
        "    base_path = '/content/drive/MyDrive/Colab Notebooks'\n",
        "    train_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Training'\n",
        "    test_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "    tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "    num_classes = len(tumor_types)\n",
        "\n",
        "    # Create checkpoint directory\n",
        "    checkpoint_dir = os.path.join(base_path, 'checkpoints')\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Data augmentation and normalization\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Create the datasets\n",
        "        train_dataset = MRIDataset(train_folder, tumor_types, transform=data_transforms['train'])\n",
        "        test_dataset = MRIDataset(test_folder, tumor_types, transform=data_transforms['val'])\n",
        "\n",
        "        print(\"Dataset sizes:\")\n",
        "        print(f\"Training: {len(train_dataset)}\")\n",
        "        print(f\"Testing: {len(test_dataset)}\")\n",
        "\n",
        "        # Train the CoAtNet-0 model\n",
        "        results, final_model = train_coatnet_model(train_dataset, test_dataset, num_classes)\n",
        "\n",
        "        # Display training results\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(\"\\nTraining Results:\")\n",
        "        print(results_df)\n",
        "\n",
        "        # Save training history\n",
        "        history_path = os.path.join(base_path, 'coatnet_0_training_history.csv')\n",
        "        results_df.to_csv(history_path, index=False)\n",
        "        print(f\"Training history saved to {history_path}\")\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "        test_acc, precision, recall, f1, auc_roc, test_loss, predictions, true_labels = evaluate_model(\n",
        "            final_model,\n",
        "            test_loader,\n",
        "            tumor_types\n",
        "        )\n",
        "\n",
        "        # Create and display metrics\n",
        "        metrics_df = create_metrics_dataframe(\n",
        "            final_model,\n",
        "            test_acc,\n",
        "            precision,\n",
        "            recall,\n",
        "            f1,\n",
        "            auc_roc,\n",
        "            results[-1]['Training Time (s)'],\n",
        "            test_loss\n",
        "        )\n",
        "        print(\"\\nModel Metrics:\")\n",
        "        print(metrics_df.to_string(index=False))\n",
        "\n",
        "        # Save metrics\n",
        "        metrics_csv_path = os.path.join(base_path, 'coatnet_0_model_metrics.csv')\n",
        "        metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "        print(f\"\\nMetrics saved to {metrics_csv_path}\")\n",
        "\n",
        "        # Save final model\n",
        "        model_path = os.path.join(base_path, 'coatnet_0_model_final.pth')\n",
        "        torch.save({\n",
        "            'epoch': len(results),\n",
        "            'model_state_dict': final_model.state_dict(),\n",
        "            'results': results,\n",
        "            'test_metrics': {\n",
        "                'accuracy': test_acc,\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1': f1,\n",
        "                'auc_roc': auc_roc,\n",
        "                'test_loss': test_loss\n",
        "            }\n",
        "        }, model_path)\n",
        "        print(f\"\\nModel saved to {model_path}\")\n",
        "\n",
        "        # Save predictions\n",
        "        predictions_df = pd.DataFrame({\n",
        "            'True_Label': [tumor_types[i] for i in true_labels],\n",
        "            'Predicted_Label': [tumor_types[i] for i in predictions]\n",
        "        })\n",
        "        predictions_path = os.path.join(base_path, 'coatnet_0_test_predictions.csv')\n",
        "        predictions_df.to_csv(predictions_path, index=False)\n",
        "        print(f\"Test predictions saved to {predictions_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        raise e\n",
        "\n",
        "    print(\"\\nCoAtNet-0 training, evaluation, and metrics logging complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kOIU17eceS9u",
      "metadata": {
        "id": "kOIU17eceS9u"
      },
      "source": [
        "Since the comp complexity a.k.a time to train is too long I will make the educated guess to not experiment with more complex co-at-net models based on the fact that research shows that accuracy doesn't improve all that much."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1J8rMFjRH-R",
      "metadata": {
        "id": "b1J8rMFjRH-R"
      },
      "source": [
        "Due to it's complex hybrid architecture, CoAtNet is nearly impossible to interpret"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J4whcLjVjszh",
      "metadata": {
        "id": "J4whcLjVjszh"
      },
      "source": [
        "## Model 9: CoAtNet1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OSQGmAvHzMeC",
      "metadata": {
        "id": "OSQGmAvHzMeC"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "\n",
        "class CoAtNet1Model(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CoAtNet1Model, self).__init__()\n",
        "\n",
        "        # Load pre-trained CoAtNet-1-RW model\n",
        "        self.coatnet = timm.create_model('coatnet_1_rw_224', pretrained=True, num_classes=0)\n",
        "\n",
        "        # Enable gradient checkpointing if available\n",
        "        if hasattr(self.coatnet, 'set_grad_checkpointing'):\n",
        "            self.coatnet.set_grad_checkpointing(enable=True)\n",
        "\n",
        "        # Get the number of features from CoAtNet-1\n",
        "        coatnet_num_features = self.coatnet.num_features\n",
        "\n",
        "        # Add final classification layers with reduced size for memory efficiency\n",
        "        # Note: CoAtNet-1 has more features than CoAtNet-0, so we add an extra reduction layer\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(coatnet_num_features, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.coatnet(x)\n",
        "        output = self.fc(features)\n",
        "        return output\n",
        "\n",
        "def initialize_coatnet_model(num_classes):\n",
        "    return CoAtNet1Model(num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "MWzKT_Q1zMze",
      "metadata": {
        "id": "MWzKT_Q1zMze"
      },
      "outputs": [],
      "source": [
        "def train_coatnet_model(train_dataset, test_dataset, num_classes, num_epochs=100, patience=10, k_folds=5):\n",
        "    results = []\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    print(\"Training with pre-trained CoAtNet-1 weights\")\n",
        "\n",
        "    # Set memory-efficient settings\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "    # Initialize gradient scaler for mixed precision\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Reduced batch size for CoAtNet-1 since it's larger\n",
        "    batch_size = 16\n",
        "\n",
        "    # K-Fold Cross-validation\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold, (train_ids, val_ids) in enumerate(kfold.split(train_dataset)):\n",
        "        print(f'FOLD {fold+1}')\n",
        "        print('--------------------------------')\n",
        "\n",
        "        train_subsampler = SubsetRandomSampler(train_ids)\n",
        "        val_subsampler = SubsetRandomSampler(val_ids)\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=train_subsampler,\n",
        "            num_workers=2,\n",
        "            pin_memory=True\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=val_subsampler,\n",
        "            num_workers=2,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        model = initialize_coatnet_model(num_classes).to(device)\n",
        "\n",
        "        # Adjusted learning rates for CoAtNet-1\n",
        "        optimizer = optim.AdamW([\n",
        "            {'params': model.coatnet.parameters(), 'lr': 5e-6},  # Lower learning rate for pre-trained layers\n",
        "            {'params': model.fc.parameters(), 'lr': 5e-5}       # Lower learning rate for new layers\n",
        "        ])\n",
        "\n",
        "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        best_model = None\n",
        "        epochs_no_improve = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Training phase\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "\n",
        "            for inputs, labels in train_loader:\n",
        "                try:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # Use mixed precision training\n",
        "                    with autocast():\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Scale gradients and optimize\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "\n",
        "                    train_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    train_total += labels.size(0)\n",
        "                    train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    # Clear cache more frequently for CoAtNet-1\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"RuntimeError in training loop: {e}\")\n",
        "                    print(f\"Input shape: {inputs.shape}\")\n",
        "                    continue\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    try:\n",
        "                        inputs, labels = inputs.to(device), labels.to(device)\n",
        "                        with autocast():\n",
        "                            outputs = model(inputs)\n",
        "                            loss = criterion(outputs, labels)\n",
        "                        val_loss += loss.item() * inputs.size(0)\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "                        val_total += labels.size(0)\n",
        "                        val_correct += (predicted == labels).sum().item()\n",
        "                    except RuntimeError as e:\n",
        "                        print(f\"RuntimeError in validation loop: {e}\")\n",
        "                        print(f\"Input shape: {inputs.shape}\")\n",
        "                        continue\n",
        "\n",
        "            # Calculate average losses and accuracies\n",
        "            train_loss = train_loss / len(train_loader.dataset)\n",
        "            val_loss = val_loss / len(val_loader.dataset)\n",
        "            train_acc = train_correct / train_total\n",
        "            val_acc = val_correct / val_total\n",
        "\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            if val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = model.state_dict()\n",
        "                epochs_no_improve = 0\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "\n",
        "            if epochs_no_improve == patience:\n",
        "                print('Early stopping!')\n",
        "                break\n",
        "\n",
        "            # Clear cache after each epoch\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        end_time = time.time()\n",
        "        training_time = end_time - start_time\n",
        "        results.append({\n",
        "            'Fold': fold+1,\n",
        "            'Best Validation Loss': best_val_loss,\n",
        "            'Training Time (s)': training_time\n",
        "        })\n",
        "\n",
        "    # Save the final model\n",
        "    torch.save({\n",
        "        'epoch': len(results),\n",
        "        'model_state_dict': best_model,\n",
        "        'results': results\n",
        "    }, 'final_pretrained_coatnet_1_model.pth')\n",
        "\n",
        "    return results, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5oDxicI-zNQS",
      "metadata": {
        "collapsed": true,
        "id": "5oDxicI-zNQS"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Setup\n",
        "    base_path = '/content/drive/MyDrive/Colab Notebooks'\n",
        "    train_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Training'\n",
        "    test_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "    tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "    num_classes = len(tumor_types)\n",
        "\n",
        "    print(\"Initializing CoAtNet-1 training pipeline...\")\n",
        "    print(f\"Number of classes: {num_classes}\")\n",
        "    print(f\"Tumor types: {tumor_types}\")\n",
        "\n",
        "    # Create checkpoint directory\n",
        "    checkpoint_dir = os.path.join(base_path, 'checkpoints')\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Data augmentation and normalization for CoAtNet-1\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.RandomAdjustSharpness(0.2),  # Added for CoAtNet-1\n",
        "            transforms.RandomAutocontrast(),        # Added for CoAtNet-1\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Create the datasets\n",
        "        train_dataset = MRIDataset(train_folder, tumor_types, transform=data_transforms['train'])\n",
        "        test_dataset = MRIDataset(test_folder, tumor_types, transform=data_transforms['val'])\n",
        "\n",
        "        print(\"\\nDataset sizes:\")\n",
        "        print(f\"Training: {len(train_dataset)}\")\n",
        "        print(f\"Testing: {len(test_dataset)}\")\n",
        "\n",
        "        # Train the CoAtNet-1 model\n",
        "        print(\"\\nInitiating CoAtNet-1 training...\")\n",
        "        results, final_model = train_coatnet_model(\n",
        "            train_dataset,\n",
        "            test_dataset,\n",
        "            num_classes,\n",
        "            num_epochs=50,    # Adjust these parameters as needed\n",
        "            patience=5,\n",
        "            k_folds=5\n",
        "        )\n",
        "\n",
        "        # Display training results\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(\"\\nTraining Results:\")\n",
        "        print(results_df)\n",
        "\n",
        "        # Save training history\n",
        "        history_path = os.path.join(base_path, 'coatnet_1_training_history.csv')\n",
        "        results_df.to_csv(history_path, index=False)\n",
        "        print(f\"\\nTraining history saved to {history_path}\")\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        print(\"\\nEvaluating model on test set...\")\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=16,  # Reduced batch size for CoAtNet-1\n",
        "            shuffle=False,\n",
        "            num_workers=2,   # Reduced workers for memory efficiency\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        test_acc, precision, recall, f1, auc_roc, test_loss, predictions, true_labels = evaluate_model(\n",
        "            final_model,\n",
        "            test_loader,\n",
        "            tumor_types\n",
        "        )\n",
        "\n",
        "        # Create and display metrics\n",
        "        metrics_df = create_metrics_dataframe(\n",
        "            final_model,\n",
        "            test_acc,\n",
        "            precision,\n",
        "            recall,\n",
        "            f1,\n",
        "            auc_roc,\n",
        "            results[-1]['Training Time (s)'],\n",
        "            test_loss\n",
        "        )\n",
        "        print(\"\\nModel Metrics:\")\n",
        "        print(metrics_df.to_string(index=False))\n",
        "\n",
        "        # Save metrics\n",
        "        metrics_csv_path = os.path.join(base_path, 'coatnet_1_model_metrics.csv')\n",
        "        metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "        print(f\"\\nMetrics saved to {metrics_csv_path}\")\n",
        "\n",
        "        # Save confusion matrix\n",
        "        cm = confusion_matrix(true_labels, predictions)\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=tumor_types,\n",
        "                   yticklabels=tumor_types)\n",
        "        plt.title('CoAtNet-1 Confusion Matrix')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(base_path, 'coatnet_1_confusion_matrix.png'))\n",
        "        plt.close()\n",
        "\n",
        "        # Save final model\n",
        "        model_path = os.path.join(base_path, 'coatnet_1_model_final.pth')\n",
        "        torch.save({\n",
        "            'epoch': len(results),\n",
        "            'model_state_dict': final_model.state_dict(),\n",
        "            'results': results,\n",
        "            'test_metrics': {\n",
        "                'accuracy': test_acc,\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1': f1,\n",
        "                'auc_roc': auc_roc,\n",
        "                'test_loss': test_loss\n",
        "            }\n",
        "        }, model_path)\n",
        "        print(f\"\\nModel saved to {model_path}\")\n",
        "\n",
        "        # Save predictions\n",
        "        predictions_df = pd.DataFrame({\n",
        "            'True_Label': [tumor_types[i] for i in true_labels],\n",
        "            'Predicted_Label': [tumor_types[i] for i in predictions]\n",
        "        })\n",
        "        predictions_path = os.path.join(base_path, 'coatnet_1_test_predictions.csv')\n",
        "        predictions_df.to_csv(predictions_path, index=False)\n",
        "        print(f\"Test predictions saved to {predictions_path}\")\n",
        "\n",
        "        # Print final summary\n",
        "        print(\"\\nFinal Summary:\")\n",
        "        print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "        print(f\"Average F1 Score: {np.mean(f1):.4f}\")\n",
        "        print(f\"Average AUC-ROC: {np.mean(auc_roc):.4f}\")\n",
        "        print(f\"Total Training Time: {results[-1]['Training Time (s)']:.2f} seconds\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nAn error occurred: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        raise e\n",
        "\n",
        "    print(\"\\nCoAtNet-1 training, evaluation, and metrics logging complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nGRJ6aAilF3m",
      "metadata": {
        "id": "nGRJ6aAilF3m"
      },
      "source": [
        "# XCiTs: Cross Covariance Image Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bb6a89AsiwZK",
      "metadata": {
        "id": "bb6a89AsiwZK"
      },
      "source": [
        "## Model 10: XCiT_small_12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m9gloWBIl9Qu",
      "metadata": {
        "id": "m9gloWBIl9Qu"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "torch._dynamo.config.suppress_errors = True\n",
        "\n",
        "class XCiTModel(nn.Module):\n",
        "    def __init__(self, num_classes, pretrained=True):\n",
        "        super(XCiTModel, self).__init__()\n",
        "\n",
        "        # Load XCiT small_12 model with pretrained parameter\n",
        "        self.xcit = timm.create_model('xcit_small_12_p8_224', pretrained=pretrained, num_classes=0)\n",
        "\n",
        "        # Enable gradient checkpointing for memory efficiency\n",
        "        self.xcit.set_grad_checkpointing(enable=True)\n",
        "\n",
        "        # Get the number of features from XCiT\n",
        "        xcit_num_features = self.xcit.num_features\n",
        "\n",
        "        # Add final classification layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(xcit_num_features, 512),  # Reduced from 1024 to 512 for memory efficiency\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.xcit(x)\n",
        "        output = self.fc(features)\n",
        "        return output\n",
        "\n",
        "def initialize_xcit_model(num_classes, pretrained=True):\n",
        "    return XCiTModel(num_classes, pretrained=pretrained)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64Vtz1Ksl9mD",
      "metadata": {
        "id": "64Vtz1Ksl9mD"
      },
      "outputs": [],
      "source": [
        "def train_xcit_model(train_dataset, test_dataset, num_classes, num_epochs=100, patience=10, k_folds=5, pretrained=True):\n",
        "    results = []\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "    print(f\"Training with {'pretrained' if pretrained else 'randomly initialized'} weights\")\n",
        "\n",
        "    # Set memory-efficient settings\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "    # Initialize gradient scaler for mixed precision\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Use smaller batch size to prevent OOM errors\n",
        "    batch_size = 16  # Reduced from 32 but can be larger than XCiT-24 since model is smaller\n",
        "\n",
        "    # K-Fold Cross-validation\n",
        "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    for fold, (train_ids, val_ids) in enumerate(kfold.split(train_dataset)):\n",
        "        print(f'FOLD {fold+1}')\n",
        "        print('--------------------------------')\n",
        "\n",
        "        train_subsampler = SubsetRandomSampler(train_ids)\n",
        "        val_subsampler = SubsetRandomSampler(val_ids)\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=train_subsampler,\n",
        "            num_workers=2,\n",
        "            pin_memory=True\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=val_subsampler,\n",
        "            num_workers=2,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "        model = initialize_xcit_model(num_classes, pretrained=pretrained).to(device)\n",
        "\n",
        "        # Use different learning rates for pretrained vs non-pretrained\n",
        "        initial_lr = 0.0001 if pretrained else 0.001\n",
        "        optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
        "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        best_model = None\n",
        "        epochs_no_improve = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Training phase\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "\n",
        "            for inputs, labels in train_loader:\n",
        "                try:\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "                    optimizer.zero_grad()\n",
        "\n",
        "                    # Use mixed precision training\n",
        "                    with autocast():\n",
        "                        outputs = model(inputs)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    # Scale gradients and optimize\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "\n",
        "                    train_loss += loss.item() * inputs.size(0)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    train_total += labels.size(0)\n",
        "                    train_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    # Clear cache periodically\n",
        "                    if torch.cuda.is_available():\n",
        "                        torch.cuda.empty_cache()\n",
        "\n",
        "                except RuntimeError as e:\n",
        "                    print(f\"RuntimeError in training loop: {e}\")\n",
        "                    print(f\"Input shape: {inputs.shape}\")\n",
        "                    continue\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for inputs, labels in val_loader:\n",
        "                    try:\n",
        "                        inputs, labels = inputs.to(device), labels.to(device)\n",
        "                        with autocast():\n",
        "                            outputs = model(inputs)\n",
        "                            loss = criterion(outputs, labels)\n",
        "                        val_loss += loss.item() * inputs.size(0)\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "                        val_total += labels.size(0)\n",
        "                        val_correct += (predicted == labels).sum().item()\n",
        "                    except RuntimeError as e:\n",
        "                        print(f\"RuntimeError in validation loop: {e}\")\n",
        "                        print(f\"Input shape: {inputs.shape}\")\n",
        "                        continue\n",
        "\n",
        "            # Calculate average losses and accuracies\n",
        "            train_loss = train_loss / len(train_loader.dataset)\n",
        "            val_loss = val_loss / len(val_loader.dataset)\n",
        "            train_acc = train_correct / train_total\n",
        "            val_acc = val_correct / val_total\n",
        "\n",
        "            print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
        "            print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "            if best_model is None or val_loss < best_val_loss:\n",
        "                best_val_loss = val_loss\n",
        "                best_model = model.state_dict()\n",
        "                epochs_no_improve = 0\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "\n",
        "            if epochs_no_improve == patience:\n",
        "                print('Early stopping!')\n",
        "                break\n",
        "\n",
        "            # Clear cache after each epoch\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        end_time = time.time()\n",
        "        training_time = end_time - start_time\n",
        "        results.append({\n",
        "            'Fold': fold+1,\n",
        "            'Best Validation Loss': best_val_loss,\n",
        "            'Training Time (s)': training_time\n",
        "        })\n",
        "\n",
        "    # Save the final model\n",
        "    torch.save({\n",
        "        'epoch': len(results),\n",
        "        'model_state_dict': best_model,\n",
        "        'results': results,\n",
        "        'pretrained': pretrained\n",
        "    }, 'final_xcit_small_12_model.pth')\n",
        "\n",
        "    return results, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GISmuvECl-D1",
      "metadata": {
        "id": "GISmuvECl-D1"
      },
      "outputs": [],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Setup\n",
        "    base_path = '/content/drive/MyDrive/Colab Notebooks'\n",
        "    train_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Training'\n",
        "    test_folder = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "    tumor_types = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "    num_classes = len(tumor_types)\n",
        "\n",
        "    # Create checkpoint directory\n",
        "    checkpoint_dir = os.path.join(base_path, 'checkpoints')\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    # Data augmentation and normalization\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        # Create the datasets\n",
        "        train_dataset = MRIDataset(train_folder, tumor_types, transform=data_transforms['train'])\n",
        "        test_dataset = MRIDataset(test_folder, tumor_types, transform=data_transforms['val'])\n",
        "\n",
        "        print(\"Dataset sizes:\")\n",
        "        print(f\"Training: {len(train_dataset)}\")\n",
        "        print(f\"Testing: {len(test_dataset)}\")\n",
        "\n",
        "        # Train the XCiT model\n",
        "        results, final_model = train_xcit_model(train_dataset, test_dataset, num_classes)\n",
        "\n",
        "        # Display training results\n",
        "        results_df = pd.DataFrame(results)\n",
        "        print(\"\\nTraining Results:\")\n",
        "        print(results_df)\n",
        "\n",
        "        # Save training history\n",
        "        history_path = os.path.join(base_path, 'xcit_small_12_training_history.csv')\n",
        "        results_df.to_csv(history_path, index=False)\n",
        "        print(f\"Training history saved to {history_path}\")\n",
        "\n",
        "        # Evaluate on the test set\n",
        "        test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
        "        test_acc, precision, recall, f1, auc_roc, test_loss, predictions, true_labels = evaluate_model(\n",
        "            final_model,\n",
        "            test_loader,\n",
        "            tumor_types\n",
        "        )\n",
        "\n",
        "        # Create and display metrics\n",
        "        metrics_df = create_metrics_dataframe(\n",
        "            final_model,\n",
        "            test_acc,\n",
        "            precision,\n",
        "            recall,\n",
        "            f1,\n",
        "            auc_roc,\n",
        "            results[-1]['Training Time (s)'],\n",
        "            test_loss\n",
        "        )\n",
        "        print(\"\\nModel Metrics:\")\n",
        "        print(metrics_df.to_string(index=False))\n",
        "\n",
        "        # Save metrics\n",
        "        metrics_csv_path = os.path.join(base_path, 'xcit_small_12_model_metrics.csv')\n",
        "        metrics_df.to_csv(metrics_csv_path, index=False)\n",
        "        print(f\"\\nMetrics saved to {metrics_csv_path}\")\n",
        "\n",
        "        # Save final model\n",
        "        model_path = os.path.join(base_path, 'xcit_small_12_model_final.pth')\n",
        "        torch.save({\n",
        "            'epoch': len(results),\n",
        "            'model_state_dict': final_model.state_dict(),\n",
        "            'results': results,\n",
        "            'test_metrics': {\n",
        "                'accuracy': test_acc,\n",
        "                'precision': precision,\n",
        "                'recall': recall,\n",
        "                'f1': f1,\n",
        "                'auc_roc': auc_roc,\n",
        "                'test_loss': test_loss\n",
        "            }\n",
        "        }, model_path)\n",
        "        print(f\"\\nModel saved to {model_path}\")\n",
        "\n",
        "        # Save predictions\n",
        "        predictions_df = pd.DataFrame({\n",
        "            'True_Label': [tumor_types[i] for i in true_labels],\n",
        "            'Predicted_Label': [tumor_types[i] for i in predictions]\n",
        "        })\n",
        "        predictions_path = os.path.join(base_path, 'xcit_small_12_test_predictions.csv')\n",
        "        predictions_df.to_csv(predictions_path, index=False)\n",
        "        print(f\"Test predictions saved to {predictions_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        traceback.print_exc()\n",
        "        raise e\n",
        "\n",
        "    print(\"\\nXCiT Small 12 training, evaluation, and metrics logging complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mq0E-Rwvmp76",
      "metadata": {
        "id": "mq0E-Rwvmp76"
      },
      "source": [
        "# Visualising The Results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Rk6p2FqV-ndI",
      "metadata": {
        "id": "Rk6p2FqV-ndI"
      },
      "source": [
        "### Loading the model metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HVPYims9SMZE",
      "metadata": {
        "id": "HVPYims9SMZE"
      },
      "outputs": [],
      "source": [
        "def load_model_metrics():\n",
        "    # Dictionary to store file paths\n",
        "    file_paths = {\n",
        "        'ResNet50': '/content/drive/MyDrive/Colab Notebooks/resnet50_metrics.csv',\n",
        "        'ResNet101': '/content/drive/MyDrive/Colab Notebooks/resnet101_metrics.csv',\n",
        "        'EfficientNetB0': '/content/drive/MyDrive/Colab Notebooks/efficientnet_b0_model_metrics.csv',\n",
        "        'EfficientNetB1': '/content/drive/MyDrive/Colab Notebooks/efficientnet_b1_model_metrics.csv',\n",
        "        'Vit': '/content/drive/MyDrive/Colab Notebooks/vit_small_model_metrics.csv',\n",
        "        'Levit256': '/content/drive/MyDrive/Colab Notebooks/levit_256_model_metrics.csv',\n",
        "        'Levit384': '/content/drive/MyDrive/Colab Notebooks/levit_384_model_metrics.csv',\n",
        "        'CoAtNet0': '/content/drive/MyDrive/Colab Notebooks/coatnet_0_model_metrics.csv',\n",
        "        'CoAtNet1': '/content/drive/MyDrive/Colab Notebooks/coatnet_1_model_metrics.csv',\n",
        "        'XCiT': '/content/drive/MyDrive/Colab Notebooks/xcit_small_12_model_metrics.csv'\n",
        "    }\n",
        "\n",
        "    # Dictionary to store dataframes\n",
        "    dataframes = {}\n",
        "\n",
        "    # Load each CSV file into a dataframe\n",
        "    for model_name, file_path in file_paths.items():\n",
        "        try:                                #error handling\n",
        "            if os.path.exists(file_path):\n",
        "                df = pd.read_csv(file_path)\n",
        "                dataframes[model_name] = df\n",
        "                print(f\"Successfully loaded {model_name} metrics\")\n",
        "            else:\n",
        "                print(f\"Warning: File not found for {model_name} at {file_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {model_name} metrics: {str(e)}\")\n",
        "\n",
        "    return dataframes\n",
        "\n",
        "# Load all model metrics\n",
        "model_metrics = load_model_metrics()\n",
        "\n",
        "# You can access individual dataframes like this:\n",
        "# resnet50_df = model_metrics['ResNet50']\n",
        "# efficientnet_b0_df = model_metrics['EfficientNetB0']\n",
        "# etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nlWWATTTSof7",
      "metadata": {
        "id": "nlWWATTTSof7"
      },
      "outputs": [],
      "source": [
        "resnet50_df = model_metrics['ResNet50']\n",
        "resnet50_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QbDz0_uyS6xR",
      "metadata": {
        "id": "QbDz0_uyS6xR"
      },
      "outputs": [],
      "source": [
        "def merge_model_metrics(model_metrics):\n",
        "    \"\"\"\n",
        "    Merge all model metrics dataframes into a single dataframe where each row\n",
        "    represents a model and columns are the different metrics.\n",
        "\n",
        "    Args:\n",
        "        model_metrics (dict): Dictionary of dataframes keyed by model name\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: Combined dataframe with one row per model\n",
        "    \"\"\"\n",
        "    # Initialize list to store model data\n",
        "    all_model_data = []\n",
        "\n",
        "    # Process each model's dataframe\n",
        "    for model_name, df in model_metrics.items():\n",
        "        # Create a dictionary for this model's metrics\n",
        "        model_data = {'model': model_name}\n",
        "\n",
        "        # Add each metric to the dictionary\n",
        "        for _, row in df.iterrows():\n",
        "            metric_name = row['Metric'].lower().replace(' ', '_')\n",
        "            if '(' in metric_name:  # Handle metrics with units\n",
        "                metric_name = metric_name.split('(')[0].strip('_')\n",
        "            model_data[metric_name] = row['Value']\n",
        "\n",
        "        all_model_data.append(model_data)\n",
        "\n",
        "    # Create final dataframe\n",
        "    merged_df = pd.DataFrame(all_model_data)\n",
        "\n",
        "    # Ensure consistent column ordering\n",
        "    desired_columns = ['model', 'overall_accuracy', 'f1_score',\n",
        "                      'cross_entropy_loss', 'training_time',\n",
        "                      'number_of_parameters', 'model_size']\n",
        "\n",
        "    # Filter columns to only include those that exist\n",
        "    final_columns = ['model'] + [col for col in desired_columns[1:]\n",
        "                                if col in merged_df.columns]\n",
        "\n",
        "    merged_df = merged_df[final_columns]\n",
        "\n",
        "    print(f\"Successfully merged {len(model_metrics)} models\")\n",
        "    print(f\"Columns in final dataframe: {merged_df.columns.tolist()}\")\n",
        "\n",
        "    return merged_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bdbz2Dze012",
      "metadata": {
        "id": "9bdbz2Dze012"
      },
      "outputs": [],
      "source": [
        "# Using the model_metrics dictionary from the previous code\n",
        "merged_metrics = merge_model_metrics(model_metrics)\n",
        "\n",
        "merged_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EfEIDnBTnMum",
      "metadata": {
        "id": "EfEIDnBTnMum"
      },
      "source": [
        "### Best accuracy (bar chart)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qJvZvgRijcQz",
      "metadata": {
        "id": "qJvZvgRijcQz"
      },
      "outputs": [],
      "source": [
        "# Sort the dataframe by accuracy\n",
        "sorted_metrics = merged_metrics.sort_values('overall_accuracy')\n",
        "\n",
        "# Create figure with larger size\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create the bar plot with sorted data\n",
        "bars = plt.bar(sorted_metrics['model'], sorted_metrics['overall_accuracy'], color='cornflowerblue')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Model Accuracy Comparison', pad=20, size=14)\n",
        "plt.xlabel('Model', labelpad=10)\n",
        "plt.ylabel('Accuracy', labelpad=10)\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Set y-axis limits to focus on 85-100% range with extra space for labels\n",
        "plt.ylim(0.85, 1.01)\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
        "\n",
        "# Format y-axis as percentages\n",
        "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n",
        "\n",
        "# Add value labels on top of each bar with padding\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.002,\n",
        "             f'{height:.1%}',\n",
        "             ha='center', va='bottom')\n",
        "\n",
        "# Adjust layout to prevent label cutoff\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "R4t2lDk5C9h9",
      "metadata": {
        "id": "R4t2lDk5C9h9"
      },
      "source": [
        "### Best F1 scores (Bar Chart)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5RmJES9lI3vm",
      "metadata": {
        "id": "5RmJES9lI3vm"
      },
      "outputs": [],
      "source": [
        "# Sort the dataframe by F1 score\n",
        "sorted_metrics = merged_metrics.sort_values('f1_score')\n",
        "\n",
        "# Create figure with larger size\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create the bar plot with sorted data\n",
        "bars = plt.bar(sorted_metrics['model'], sorted_metrics['f1_score'], color='cornflowerblue')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Model F1 Score Comparison', pad=20, size=14)\n",
        "plt.xlabel('Model', labelpad=10)\n",
        "plt.ylabel('F1 Score', labelpad=10)\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Set y-axis limits to focus on 85-100% range with extra space for labels\n",
        "plt.ylim(0.85, 1.01)\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
        "\n",
        "# Format y-axis as percentages\n",
        "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n",
        "\n",
        "# Add value labels on top of each bar with padding\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.002,\n",
        "             f'{height:.1%}',\n",
        "             ha='center', va='bottom')\n",
        "\n",
        "# Adjust layout to prevent label cutoff\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "KI1eqJ_HDEX5",
      "metadata": {
        "id": "KI1eqJ_HDEX5"
      },
      "source": [
        "### Accuracy (x-axis) , F1 score (y -axis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VL3KyZ4PJGDT",
      "metadata": {
        "id": "VL3KyZ4PJGDT"
      },
      "outputs": [],
      "source": [
        "# Create figure with a square aspect ratio\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# Create the scatter plot\n",
        "plt.scatter(merged_metrics['overall_accuracy'],\n",
        "           merged_metrics['f1_score'],\n",
        "           alpha=0.6,\n",
        "           s=100)  # Increase point size for better visibility\n",
        "\n",
        "# Add labels for each point\n",
        "for i, model in enumerate(merged_metrics['model']):\n",
        "    plt.annotate(model,\n",
        "                (merged_metrics['overall_accuracy'].iloc[i],\n",
        "                 merged_metrics['f1_score'].iloc[i]),\n",
        "                xytext=(5, 5),  # Small offset for label\n",
        "                textcoords='offset points')\n",
        "\n",
        "# Add a diagonal line representing y=x\n",
        "min_val = min(merged_metrics['overall_accuracy'].min(),\n",
        "              merged_metrics['f1_score'].min())\n",
        "max_val = max(merged_metrics['overall_accuracy'].max(),\n",
        "              merged_metrics['f1_score'].max())\n",
        "plt.plot([min_val, max_val], [min_val, max_val],\n",
        "         'k--', alpha=0.3, label='y=x')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Model Performance: Accuracy vs F1 Score', pad=20, size=14)\n",
        "plt.xlabel('Accuracy', labelpad=10)\n",
        "plt.ylabel('F1 Score', labelpad=10)\n",
        "\n",
        "# Format axes as percentages\n",
        "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: '{:.1%}'.format(x)))\n",
        "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "# Set axis limits with some padding\n",
        "padding = 0.01\n",
        "plt.xlim(min_val - padding, max_val + padding)\n",
        "plt.ylim(min_val - padding, max_val + padding)\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Make axes equal to preserve the square aspect ratio\n",
        "plt.axis('equal')\n",
        "\n",
        "# Adjust layout to prevent label cutoff\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "kqmvm_p8nM2Q",
      "metadata": {
        "id": "kqmvm_p8nM2Q"
      },
      "source": [
        "### Accuracy against number of paramters (scatter plot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zjh_SPNgkEq3",
      "metadata": {
        "id": "zjh_SPNgkEq3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create figure with larger size\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Create scatter plot\n",
        "plt.scatter(merged_metrics['number_of_parameters'],\n",
        "           merged_metrics['overall_accuracy'],\n",
        "           alpha=0.6,\n",
        "           s=100)  # s controls point size\n",
        "\n",
        "# Add labels for each point\n",
        "for i, model in enumerate(merged_metrics['model']):\n",
        "    plt.annotate(model,\n",
        "                (merged_metrics['number_of_parameters'].iloc[i],\n",
        "                 merged_metrics['overall_accuracy'].iloc[i]),\n",
        "                xytext=(5, 5),\n",
        "                textcoords='offset points')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Model Accuracy vs Number of Parameters', pad=20, size=14)\n",
        "plt.xlabel('Number of Parameters (millions)', labelpad=10)\n",
        "plt.ylabel('Accuracy', labelpad=10)\n",
        "\n",
        "# Format x-axis in millions\n",
        "plt.gca().xaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: '{:.1f}M'.format(x/1e6)))\n",
        "\n",
        "# Format y-axis as percentages\n",
        "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "# Set y-axis limits to focus on relevant range\n",
        "plt.ylim(0.85, 1.02)\n",
        "\n",
        "# Adjust layout to prevent label cutoff\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "DPwORO7uqe2m",
      "metadata": {
        "id": "DPwORO7uqe2m"
      },
      "source": [
        "### Time to train (bar chart)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pQBM6WnCqcYE",
      "metadata": {
        "id": "pQBM6WnCqcYE"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sort the dataframe by training time\n",
        "sorted_metrics = merged_metrics.sort_values('training_time')\n",
        "\n",
        "# Create figure with larger size\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create the bar plot with sorted data\n",
        "bars = plt.bar(sorted_metrics['model'], sorted_metrics['training_time'], color='cornflowerblue')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Model Training Time Comparison', pad=20, size=14)\n",
        "plt.xlabel('Model', labelpad=10)\n",
        "plt.ylabel('Training Time (hours)', labelpad=10)\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
        "\n",
        "# Format y-axis in hours\n",
        "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.1f}h'.format(y/3600)))\n",
        "\n",
        "# Add value labels on top of each bar with padding\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height + 50,  # Added padding\n",
        "             f'{height/3600:.1f}h',\n",
        "             ha='center', va='bottom')\n",
        "\n",
        "# Adjust layout to prevent label cutoff\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fzvT8ymTDaIz",
      "metadata": {
        "id": "fzvT8ymTDaIz"
      },
      "source": [
        "### Accuracy vs Training time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DhYmOrOwORzH",
      "metadata": {
        "id": "DhYmOrOwORzH"
      },
      "outputs": [],
      "source": [
        "# Create figure with a larger width to better show time distribution\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create the scatter plot\n",
        "plt.scatter(merged_metrics['training_time'],\n",
        "           merged_metrics['overall_accuracy'],\n",
        "           alpha=0.6,\n",
        "           s=100)  # Increase point size for better visibility\n",
        "\n",
        "# Add labels for each point\n",
        "for i, model in enumerate(merged_metrics['model']):\n",
        "    plt.annotate(model,\n",
        "                (merged_metrics['training_time'].iloc[i],\n",
        "                 merged_metrics['overall_accuracy'].iloc[i]),\n",
        "                xytext=(5, 5),  # Small offset for label\n",
        "                textcoords='offset points')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Model Performance: Accuracy vs Training Time', pad=20, size=14)\n",
        "plt.xlabel('Training Time (seconds)', labelpad=10)\n",
        "plt.ylabel('Accuracy', labelpad=10)\n",
        "\n",
        "# Format y-axis as percentage\n",
        "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "# Set y-axis limits to focus on the relevant accuracy range with padding\n",
        "y_min = merged_metrics['overall_accuracy'].min() - 0.02\n",
        "y_max = merged_metrics['overall_accuracy'].max() + 0.02\n",
        "plt.ylim(y_min, y_max)\n",
        "\n",
        "# Add some padding to x-axis\n",
        "x_max = merged_metrics['training_time'].max() * 1.05\n",
        "plt.xlim(0, x_max)\n",
        "\n",
        "# Adjust layout to prevent label cutoff\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5H6GW8hoOcdb",
      "metadata": {
        "id": "5H6GW8hoOcdb"
      },
      "source": [
        "Vit and ResNet101 stick out as being the less efficient models to train"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "iDOT1cDADeP3",
      "metadata": {
        "id": "iDOT1cDADeP3"
      },
      "source": [
        "### Training time against number of parameters\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Gy8OntbjPHe8",
      "metadata": {
        "id": "Gy8OntbjPHe8"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Create figure with a larger width\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create the scatter plot with number of parameters scaled to millions\n",
        "plt.scatter(merged_metrics['number_of_parameters'] / 1e6,\n",
        "           merged_metrics['training_time'],\n",
        "           alpha=0.6,\n",
        "           s=100)  # Increase point size for better visibility\n",
        "\n",
        "# Add labels for each point\n",
        "for i, model in enumerate(merged_metrics['model']):\n",
        "    plt.annotate(model,\n",
        "                (merged_metrics['number_of_parameters'].iloc[i] / 1e6,\n",
        "                 merged_metrics['training_time'].iloc[i]),\n",
        "                xytext=(5, 5),  # Small offset for label\n",
        "                textcoords='offset points')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Model Training Time vs Number of Parameters', pad=20, size=14)\n",
        "plt.xlabel('Number of Parameters (millions)', labelpad=10)\n",
        "plt.ylabel('Training Time (seconds)', labelpad=10)\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "# Start both axes at 0 since neither can be negative\n",
        "plt.xlim(0, (merged_metrics['number_of_parameters'].max() / 1e6) * 1.05)\n",
        "plt.ylim(0, merged_metrics['training_time'].max() * 1.05)\n",
        "\n",
        "# Add a trend line\n",
        "z = np.polyfit(merged_metrics['number_of_parameters'] / 1e6,\n",
        "               merged_metrics['training_time'], 1)\n",
        "p = np.poly1d(z)\n",
        "x_trend = np.linspace(0, merged_metrics['number_of_parameters'].max() / 1e6, 100)\n",
        "plt.plot(x_trend, p(x_trend), \"r--\", alpha=0.8,\n",
        "         label=f'Trend line (R² = {r2_score(merged_metrics[\"training_time\"], p(merged_metrics[\"number_of_parameters\"] / 1e6)):.3f})')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Adjust layout to prevent label cutoff\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qT0CdejoPRR_",
      "metadata": {
        "id": "qT0CdejoPRR_"
      },
      "source": [
        "Training time depends on model architecture more than number of parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "GXFEQbecSOdQ",
      "metadata": {
        "id": "GXFEQbecSOdQ"
      },
      "source": [
        "### Accuracy vs number of parametes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T0NYPCKMSnaL",
      "metadata": {
        "id": "T0NYPCKMSnaL"
      },
      "outputs": [],
      "source": [
        "# Create figure\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create the scatter plot with number of parameters scaled to millions\n",
        "plt.scatter(merged_metrics['number_of_parameters'] / 1e6,\n",
        "           merged_metrics['overall_accuracy'],\n",
        "           alpha=0.6,\n",
        "           s=100)\n",
        "\n",
        "# Add labels for each point\n",
        "for i, model in enumerate(merged_metrics['model']):\n",
        "    plt.annotate(model,\n",
        "                (merged_metrics['number_of_parameters'].iloc[i] / 1e6,\n",
        "                 merged_metrics['overall_accuracy'].iloc[i]),\n",
        "                xytext=(5, 5),\n",
        "                textcoords='offset points')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Model Accuracy vs Number of Parameters', pad=20, size=14)\n",
        "plt.xlabel('Number of Parameters (millions)', labelpad=10)\n",
        "plt.ylabel('Accuracy', labelpad=10)\n",
        "\n",
        "# Format y-axis as percentage\n",
        "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: '{:.1%}'.format(y)))\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.3)\n",
        "\n",
        "# Start x-axis at 0 since parameters can't be negative\n",
        "plt.xlim(0, (merged_metrics['number_of_parameters'].max() / 1e6) * 1.05)\n",
        "\n",
        "# Set y-axis limits to focus on the relevant accuracy range with padding\n",
        "y_min = merged_metrics['overall_accuracy'].min() - 0.02\n",
        "y_max = merged_metrics['overall_accuracy'].max() + 0.02\n",
        "plt.ylim(y_min, y_max)\n",
        "\n",
        "# Add trend line\n",
        "z = np.polyfit(merged_metrics['number_of_parameters'] / 1e6,\n",
        "               merged_metrics['overall_accuracy'], 1)\n",
        "p = np.poly1d(z)\n",
        "x_trend = np.linspace(0, merged_metrics['number_of_parameters'].max() / 1e6, 100)\n",
        "plt.plot(x_trend, p(x_trend), \"r--\", alpha=0.8,\n",
        "         label=f'Trend line (R² = {r2_score(merged_metrics[\"overall_accuracy\"], p(merged_metrics[\"number_of_parameters\"] / 1e6)):.3f})')\n",
        "\n",
        "# Add legend\n",
        "plt.legend()\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tpfEdoHtnNA6",
      "metadata": {
        "id": "tpfEdoHtnNA6"
      },
      "source": [
        "### Inference time (bar chart)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "585vNr-0EhQk",
      "metadata": {
        "id": "585vNr-0EhQk"
      },
      "source": [
        "##### Loading the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_l3AsSOkH-b8",
      "metadata": {
        "collapsed": true,
        "id": "_l3AsSOkH-b8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from typing import Dict, NamedTuple\n",
        "from torch import nn\n",
        "\n",
        "class Models(NamedTuple):\n",
        "    resnet50: nn.Module\n",
        "    resnet101: nn.Module\n",
        "    efficientnetb0: nn.Module\n",
        "    efficientnetb1: nn.Module\n",
        "    vit: nn.Module\n",
        "    levit384: nn.Module\n",
        "    levit256: nn.Module\n",
        "    xcit: nn.Module\n",
        "\n",
        "def load_models(num_classes: int, base_path: str = '/content/drive/MyDrive/Colab Notebooks/') -> Models:\n",
        "    \"\"\"Load all pretrained models and return them as a named tuple\"\"\"\n",
        "    configs = {\n",
        "        'resnet50': (initialize_resnet50_model, 'final_mriresnet50_model.pth', None),\n",
        "        'resnet101': (initialize_model_resnet101, 'final_resnet101_classification_model.pth', None),\n",
        "        'efficientnetb0': (initialize_efficientnet0_model, 'final_efficientnet_b0_mri_classification_model.pth', None),\n",
        "        'efficientnetb1': (initialize_efficientnetb1_model, 'final_efficientnet_b1_mri_classification_model.pth', None),\n",
        "        'vit': (initialize_vit_model, 'final_vit_small_mri_classification_model.pth', None),\n",
        "        'levit384': (initialize_levit384_model, 'levit_384_model_final.pth', 'model_state_dict'),\n",
        "        'levit256': (initialize_levit256_model, 'levit_256_model_final.pth', 'model_state_dict'),\n",
        "        'xcit': (initialize_xcit_model, 'xcit_small_12_model_final.pth', 'model_state_dict')\n",
        "    }\n",
        "\n",
        "    loaded = {}\n",
        "    for name, (initializer, path, state_dict_key) in configs.items():\n",
        "        model_path = os.path.join(base_path, path)\n",
        "        if not os.path.exists(model_path):\n",
        "            raise FileNotFoundError(f\"{name} weights not found at {model_path}\")\n",
        "\n",
        "        try:\n",
        "            model_classes = num_classes if name not in ['levit384', 'levit256', 'xcit'] else 4\n",
        "            model = initializer(num_classes=model_classes)\n",
        "            weights = torch.load(model_path)\n",
        "            if state_dict_key:\n",
        "                weights = weights[state_dict_key]\n",
        "            model.load_state_dict(weights)\n",
        "            model.eval()\n",
        "            loaded[name] = model\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(f\"Error loading {name}: {str(e)}\")\n",
        "\n",
        "    return Models(**loaded)\n",
        "\n",
        "# Load all models into a named tuple\n",
        "models = load_models(num_classes=len(tumor_types))\n",
        "\n",
        "# Now you can access models directly:\n",
        "# models.resnet50\n",
        "# models.vit\n",
        "# models.xcit\n",
        "# etc."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BsNhFq9KEoJ_",
      "metadata": {
        "id": "BsNhFq9KEoJ_"
      },
      "source": [
        "##### Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3nqt0cJ_U6Bw",
      "metadata": {
        "id": "3nqt0cJ_U6Bw"
      },
      "outputs": [],
      "source": [
        "import statistics\n",
        "\n",
        "def measure_inference_time(model, model_name, test_folder, tumor_types, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    inference_times = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for tumor_type in tumor_types:\n",
        "            tumor_folder = os.path.join(test_folder, tumor_type)\n",
        "            for img_name in os.listdir(tumor_folder):\n",
        "                if img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
        "                    img_path = os.path.join(tumor_folder, img_name)\n",
        "                    image = Image.open(img_path).convert('RGB')\n",
        "                    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "                    if device == 'cuda':\n",
        "                        torch.cuda.empty_cache()\n",
        "                        torch.cuda.synchronize()\n",
        "\n",
        "                    start_time = time.time()\n",
        "                    _ = model(input_tensor)\n",
        "                    torch.cuda.synchronize()\n",
        "                    inference_times.append(time.time() - start_time)\n",
        "\n",
        "    avg_time = statistics.mean(inference_times)\n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'Avg Inference Time (ms)': avg_time * 1000,\n",
        "        'FPS': 1.0 / avg_time,\n",
        "        'Total Images': len(inference_times)\n",
        "    }\n",
        "\n",
        "# Dictionary mapping for model names\n",
        "model_names = {\n",
        "    'ResNet-50': models.resnet50,\n",
        "    'ResNet-101': models.resnet101,\n",
        "    'EfficientNet-B0': models.efficientnetb0,\n",
        "    'EfficientNet-B1': models.efficientnetb1,\n",
        "    'ViT-Small': models.vit,\n",
        "    'LeViT-384': models.levit384,\n",
        "    'LeViT-256': models.levit256,\n",
        "    'XCiT-Small': models.xcit\n",
        "}\n",
        "\n",
        "# Run comparison\n",
        "results = []\n",
        "for model_name, model in model_names.items():\n",
        "    print(f\"\\nProcessing {model_name}...\")\n",
        "    metrics = measure_inference_time(model, model_name, test_folder, tumor_types)\n",
        "    results.append(metrics)\n",
        "\n",
        "# Create and display DataFrame\n",
        "df = pd.DataFrame(results)\n",
        "df = df.sort_values('Avg Inference Time (ms)')\n",
        "df[['Avg Inference Time (ms)', 'FPS']] = df[['Avg Inference Time (ms)', 'FPS']].round(2)\n",
        "\n",
        "print(\"\\nInference Time Comparison:\")\n",
        "print(df)\n",
        "df.to_csv('inference_times.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TqOYwiwWErwJ",
      "metadata": {
        "id": "TqOYwiwWErwJ"
      },
      "source": [
        "##### Plotting:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7xob2ODTZWJN",
      "metadata": {
        "id": "7xob2ODTZWJN"
      },
      "outputs": [],
      "source": [
        "# Clean up model names to match between dataframes\n",
        "inference_df = df.copy()\n",
        "\n",
        "# Create a mapping dictionary for model names with exact matches from the first dataframe\n",
        "name_mapping = {\n",
        "    'ViT-Small': 'Vit',\n",
        "    'ResNet-50': 'ResNet50',\n",
        "    'EfficientNet-B0': 'EfficientNetB0',\n",
        "    'ResNet-101': 'ResNet101',\n",
        "    'EfficientNet-B1': 'EfficientNetB1',\n",
        "    'LeViT-256': 'Levit256',\n",
        "    'LeViT-384': 'Levit384',\n",
        "    'XCiT-Small': 'XCiT'  # Fixed to match exactly with first dataframe\n",
        "}\n",
        "\n",
        "# Apply the mapping\n",
        "inference_df['Model'] = inference_df['Model'].map(name_mapping)\n",
        "\n",
        "# Merge the dataframes\n",
        "merged_complete = merged_metrics.merge(inference_df, left_on='model', right_on='Model', how='inner')\n",
        "\n",
        "# Create the bar chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create the bar plot with sorted data\n",
        "sorted_data = merged_complete.sort_values('Avg Inference Time (ms)')\n",
        "bars = plt.bar(sorted_data['model'], sorted_data['Avg Inference Time (ms)'], color='cornflowerblue')\n",
        "\n",
        "# Customize the plot\n",
        "plt.title('Model Inference Time Comparison', pad=20, size=14)\n",
        "plt.xlabel('Model', labelpad=10)\n",
        "plt.ylabel('Average Inference Time (ms)', labelpad=10)\n",
        "\n",
        "# Rotate x-axis labels for better readability\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Add grid for better readability\n",
        "plt.grid(True, linestyle='--', alpha=0.7, axis='y')\n",
        "\n",
        "# Add value labels on top of each bar with padding\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.2,\n",
        "             f'{height:.2f}ms',\n",
        "             ha='center', va='bottom')\n",
        "\n",
        "# Adjust layout to prevent label cutoff\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m_LOyYIqnNFJ",
      "metadata": {
        "id": "m_LOyYIqnNFJ"
      },
      "source": [
        "# Visualizing Interpretability"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "O3TQdJ28tUIU",
      "metadata": {
        "id": "O3TQdJ28tUIU"
      },
      "source": [
        "### Selecting the same pictures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rqu07lz6kjJU",
      "metadata": {
        "id": "Rqu07lz6kjJU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_random_samples(test_folder, samples_per_category=10, seed=None):\n",
        "    \"\"\"\n",
        "    Displays random samples of MRI images from each tumor category.\n",
        "\n",
        "    Args:\n",
        "        test_folder (str): Path to the test folder containing tumor type subfolders\n",
        "        samples_per_category (int): Number of samples to display per category\n",
        "        seed (int, optional): Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing selected image paths for each category\n",
        "    \"\"\"\n",
        "    if seed is not None:\n",
        "        random.seed(seed)\n",
        "\n",
        "    # Get all tumor categories (subfolders)\n",
        "    tumor_categories = [d for d in os.listdir(test_folder)\n",
        "                       if os.path.isdir(os.path.join(test_folder, d))]\n",
        "\n",
        "    selected_samples = {}\n",
        "\n",
        "    # Select random samples from each category\n",
        "    for category in tumor_categories:\n",
        "        category_path = os.path.join(test_folder, category)\n",
        "        image_files = [f for f in os.listdir(category_path)\n",
        "                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        # Select random samples\n",
        "        selected_images = random.sample(image_files,\n",
        "                                      min(samples_per_category, len(image_files)))\n",
        "        selected_samples[category] = selected_images\n",
        "\n",
        "        # Display the samples\n",
        "        plt.figure(figsize=(20, 4))\n",
        "        plt.suptitle(f'Category: {category}')\n",
        "\n",
        "        for idx, img_name in enumerate(selected_images, 1):\n",
        "            img_path = os.path.join(category_path, img_name)\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "            plt.subplot(2, 5, idx)\n",
        "            plt.imshow(img)\n",
        "            plt.title(f'File: {img_name}')\n",
        "            plt.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return selected_samples\n",
        "\n",
        "# Example usage:\n",
        "# selected_images = display_random_samples(test_folder='/content/drive/MyDrive/Colab Notebooks/Resized_Testing')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wZJbKL9l-q1P",
      "metadata": {
        "id": "wZJbKL9l-q1P"
      },
      "outputs": [],
      "source": [
        "selected_images = display_random_samples(test_folder='/content/drive/MyDrive/Colab Notebooks/Resized_Testing')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uVD6FpYe-6eO",
      "metadata": {
        "id": "uVD6FpYe-6eO"
      },
      "outputs": [],
      "source": [
        "#images :\n",
        "# Te-gl_0261\n",
        "# Te-gl_0037\n",
        "# Te-gl_0131\n",
        "#Te-me_0224\n",
        "#Te-me_0231\n",
        "#Te-me_0162\n",
        "#Te-pi_0205\n",
        "#Te-pi_0132\n",
        "#Te-pi_0110"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kZE6wafwC4-6",
      "metadata": {
        "id": "kZE6wafwC4-6"
      },
      "outputs": [],
      "source": [
        "def load_images(test_folder, image_names):\n",
        "    # Mapping of short names to full folder names\n",
        "    folder_map = {\n",
        "        'gl': 'glioma',\n",
        "        'me': 'meningioma',\n",
        "        'pi': 'pituitary'\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i, name in enumerate(image_names, 1):\n",
        "        # Get category (gl, me, or pi)\n",
        "        category_short = name.split('-')[1].split('_')[0]\n",
        "        category_full = folder_map[category_short]\n",
        "\n",
        "        # Construct full path\n",
        "        img_path = os.path.join(test_folder, category_full, name + '.jpg')  # or whatever extension you have\n",
        "\n",
        "        # Load and display image\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        plt.subplot(3, 3, i)\n",
        "        plt.imshow(img)\n",
        "        plt.title(name)\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Images to load\n",
        "images = [\n",
        "    'Te-gl_0261',\n",
        "    'Te-gl_0037',\n",
        "    'Te-gl_0131',\n",
        "    'Te-me_0224',\n",
        "    'Te-me_0231',\n",
        "    'Te-me_0162',\n",
        "    'Te-pi_0205',\n",
        "    'Te-pi_0132',\n",
        "    'Te-pi_0110'\n",
        "]\n",
        "\n",
        "# Use it like this:\n",
        "load_images('/content/drive/MyDrive/Colab Notebooks/Resized_Testing', images)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pcAwlEointHb",
      "metadata": {
        "id": "pcAwlEointHb"
      },
      "source": [
        "### Grad-Cam (Resnets, EfficientNets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qg6kp6pEBPfS",
      "metadata": {
        "id": "qg6kp6pEBPfS"
      },
      "outputs": [],
      "source": [
        "# 1 - take the 9 images\n",
        "# 2 - does their gradcam for each of the 4 models\n",
        "# 3 - plot them side by side"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5j4Qc2czILt4",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5j4Qc2czILt4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from torchvision import transforms\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "\n",
        "def get_model_specific_params(model_name):\n",
        "    \"\"\"Returns model-specific parameters for GradCAM\"\"\"\n",
        "    params = {\n",
        "        'resnet50': {\n",
        "            'target_layer': 'layer4',\n",
        "            'input_size': 224,\n",
        "            'layer_getter': lambda model: model.layer4[-1]\n",
        "        },\n",
        "        'resnet101': {\n",
        "            'target_layer': 'layer4',\n",
        "            'input_size': 224,\n",
        "            'layer_getter': lambda model: model.layer4[-1]\n",
        "        },\n",
        "        'efficientnetb0': {\n",
        "            'target_layer': 'features.8',\n",
        "            'input_size': 224,\n",
        "            'layer_getter': lambda model: model.features[8]\n",
        "        },\n",
        "        'efficientnetb1': {\n",
        "            'target_layer': 'features.8',\n",
        "            'input_size': 240,\n",
        "            'layer_getter': lambda model: model.features[8]\n",
        "        }\n",
        "    }\n",
        "    return params[model_name]\n",
        "\n",
        "def get_gradcam_for_image(model, model_name, image_path, training_order):\n",
        "    \"\"\"Generate GradCAM visualization for a single model and image\"\"\"\n",
        "    try:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = model.to(device)\n",
        "        model_params = get_model_specific_params(model_name)\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((model_params['input_size'], model_params['input_size'])),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # Load and preprocess image\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        # Setup GradCAM\n",
        "        target_layer = model_params['layer_getter'](model)\n",
        "        grad_cam = GradCAM(\n",
        "            model=model,\n",
        "            target_layers=[target_layer],\n",
        "            reshape_transform=None\n",
        "        )\n",
        "\n",
        "        # Get prediction and confidence\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "            prediction = torch.argmax(output).item()\n",
        "            confidence = probabilities[0][prediction].item() * 100\n",
        "\n",
        "        # Generate GradCAM\n",
        "        targets = [ClassifierOutputTarget(prediction)]\n",
        "        grayscale_cam = grad_cam(input_tensor=input_tensor, targets=targets)\n",
        "        grayscale_cam = grayscale_cam[0, :]\n",
        "\n",
        "        rgb_img = np.array(image.resize((model_params['input_size'], model_params['input_size']))) / 255.0\n",
        "        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
        "\n",
        "        return visualization, confidence, prediction\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path} with {model_name}: {str(e)}\")\n",
        "        return None, None, None\n",
        "\n",
        "def visualize_multiple_models_gradcam(models_dict, image_list, test_folder, training_order):\n",
        "    \"\"\"\n",
        "    Visualize GradCAM for multiple images across different models\n",
        "    \"\"\"\n",
        "    folder_map = {\n",
        "        'gl': 'glioma',\n",
        "        'me': 'meningioma',\n",
        "        'pi': 'pituitary'\n",
        "    }\n",
        "\n",
        "    # Calculate grid dimensions\n",
        "    n_images = len(image_list)\n",
        "    n_models = len(models_dict)\n",
        "\n",
        "    plt.figure(figsize=(4 * n_models, 3 * n_images))\n",
        "\n",
        "    for img_idx, img_name in enumerate(image_list):\n",
        "        # Get category and construct full path\n",
        "        category_short = img_name.split('-')[1].split('_')[0]\n",
        "        category_full = folder_map[category_short]\n",
        "        img_path = os.path.join(test_folder, category_full, img_name + '.jpg')\n",
        "\n",
        "        # Load original image for reference\n",
        "        original_img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # Plot original image\n",
        "        plt.subplot(n_images, n_models + 1, img_idx * (n_models + 1) + 1)\n",
        "        plt.imshow(original_img)\n",
        "        plt.title(f'Original\\n{img_name}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Generate and plot GradCAM for each model\n",
        "        for model_idx, (model_name, model) in enumerate(models_dict.items(), 1):\n",
        "            vis, conf, pred = get_gradcam_for_image(model, model_name.lower(), img_path, training_order)\n",
        "\n",
        "            if vis is not None:\n",
        "                plt.subplot(n_images, n_models + 1, img_idx * (n_models + 1) + model_idx + 1)\n",
        "                plt.imshow(vis)\n",
        "                plt.title(f'{model_name}\\nConf: {conf:.1f}%\\nPred: {training_order[pred]}')\n",
        "                plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Use it like this:\n",
        "models_dict = {\n",
        "    'ResNet50': models.resnet50,\n",
        "    'ResNet101': models.resnet101,\n",
        "    'EfficientNetB0': models.efficientnetb0,\n",
        "    'EfficientNetB1': models.efficientnetb1\n",
        "}\n",
        "\n",
        "images_to_process = [\n",
        "    'Te-gl_0261',\n",
        "    'Te-gl_0037',\n",
        "    'Te-gl_0131',\n",
        "    'Te-me_0224',\n",
        "    'Te-me_0231',\n",
        "    'Te-me_0162',\n",
        "    'Te-pi_0205',\n",
        "    'Te-pi_0132',\n",
        "    'Te-pi_0110'\n",
        "]\n",
        "\n",
        "training_order = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "visualize_multiple_models_gradcam(\n",
        "    models_dict=models_dict,\n",
        "    image_list=images_to_process,\n",
        "    test_folder='/content/drive/MyDrive/Colab Notebooks/Resized_Testing',\n",
        "    training_order=training_order\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2EfqDjy2KNwW",
      "metadata": {
        "collapsed": true,
        "id": "2EfqDjy2KNwW"
      },
      "outputs": [],
      "source": [
        "resnet50_model = initialize_resnet50_model(num_classes=len(tumor_types))\n",
        "resnet50_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/final_mriresnet50_model.pth'))\n",
        "resnet50_model.eval()\n",
        "resnet101_model = initialize_model_resnet101(num_classes=len(tumor_types))\n",
        "resnet101_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/final_resnet101_classification_model.pth'))\n",
        "resnet101_model.eval()\n",
        "efficientnetb0_model = initialize_efficientnetb1_model(num_classes=len(tumor_types))\n",
        "efficientnetb0_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/final_efficientnet_b1_mri_classification_model.pth'))\n",
        "efficientnetb0_model.eval()\n",
        "efficientnetb1_model = initialize_efficientnetb1_model(num_classes=len(tumor_types))\n",
        "efficientnetb1_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/final_efficientnet_b1_mri_classification_model.pth'))\n",
        "efficientnetb1_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guided BP"
      ],
      "metadata": {
        "id": "nbEIR4VyOw9R"
      },
      "id": "nbEIR4VyOw9R"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_guided_bp_for_resnet(model, image_path, training_order):\n",
        "    \"\"\"Generate Guided Backpropagation visualization for ResNet models\"\"\"\n",
        "    try:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        guided_bp_model = GuidedBackpropReLUModel(model=model, device=device)\n",
        "\n",
        "        image = Image.open(image_path)\n",
        "        if image.mode == 'L':\n",
        "            image = Image.merge('RGB', (image, image, image))\n",
        "\n",
        "        preprocess = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "        input_tensor.requires_grad = True\n",
        "\n",
        "        # Forward pass\n",
        "        output = guided_bp_model.forward(input_tensor)\n",
        "\n",
        "        # Get prediction and confidence\n",
        "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "        prediction = torch.argmax(output).item()\n",
        "        confidence = probabilities[0][prediction].item() * 100\n",
        "\n",
        "        # Create one hot output\n",
        "        one_hot = torch.zeros_like(output)\n",
        "        one_hot[0][prediction] = 1\n",
        "\n",
        "        # Backward pass\n",
        "        output.backward(gradient=one_hot)\n",
        "\n",
        "        # Get gradients\n",
        "        guided_bp_mask = input_tensor.grad[0].cpu().numpy()\n",
        "        guided_bp_mask = guided_bp_mask.transpose(1, 2, 0)\n",
        "\n",
        "        guided_bp_model.cleanup()\n",
        "\n",
        "        # Process the visualization\n",
        "        magnitude = np.sqrt(np.sum(guided_bp_mask**2, axis=2))\n",
        "        magnitude = (magnitude - magnitude.min()) / (magnitude.max() - magnitude.min() + 1e-8)\n",
        "\n",
        "        high_threshold = np.percentile(magnitude, 98)\n",
        "        mid_threshold = np.percentile(magnitude, 90)\n",
        "\n",
        "        visualization = np.zeros((224, 224, 3))\n",
        "        visualization[:,:,2] = magnitude\n",
        "        visualization[:,:,1] = magnitude * 0.8\n",
        "\n",
        "        red_mask = magnitude > high_threshold\n",
        "        blue_mask = (magnitude > mid_threshold) & (magnitude <= high_threshold)\n",
        "\n",
        "        visualization[red_mask, 0] = 1.0\n",
        "        visualization[red_mask, 1] = 0.2\n",
        "        visualization[red_mask, 2] = 0.2\n",
        "\n",
        "        visualization[blue_mask, 2] = 1.0\n",
        "        visualization[blue_mask, 1] = 0.8\n",
        "        visualization[blue_mask, 0] = 0.2\n",
        "\n",
        "        visualization = np.power(visualization, 0.7)\n",
        "\n",
        "        for i in range(3):\n",
        "            visualization[:,:,i] = gaussian_filter(visualization[:,:,i], sigma=1)\n",
        "\n",
        "        return visualization, confidence, prediction\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {str(e)}\")\n",
        "        return None, None, None\n",
        "\n",
        "def get_guided_bp_for_efficientnet(model, image_path, input_size, training_order):\n",
        "    \"\"\"Generate Guided Backpropagation visualization for EfficientNet models\"\"\"\n",
        "    try:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        guided_bp_model = GuidedBackpropReLUModel(model=model, device=device)\n",
        "\n",
        "        image = Image.open(image_path)\n",
        "        if image.mode == 'L':\n",
        "            image = Image.merge('RGB', (image, image, image))\n",
        "\n",
        "        preprocess = transforms.Compose([\n",
        "            transforms.Resize((input_size, input_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "        input_tensor.requires_grad = True\n",
        "\n",
        "        # Forward pass\n",
        "        output = guided_bp_model.forward(input_tensor)\n",
        "\n",
        "        # Get prediction and confidence\n",
        "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "        prediction = torch.argmax(output).item()\n",
        "        confidence = probabilities[0][prediction].item() * 100\n",
        "\n",
        "        # Create one hot output\n",
        "        one_hot = torch.zeros_like(output)\n",
        "        one_hot[0][prediction] = 1\n",
        "\n",
        "        # Backward pass\n",
        "        output.backward(gradient=one_hot)\n",
        "\n",
        "        # Get gradients\n",
        "        guided_bp_mask = input_tensor.grad[0].cpu().numpy()\n",
        "        guided_bp_mask = guided_bp_mask.transpose(1, 2, 0)\n",
        "\n",
        "        guided_bp_model.cleanup()\n",
        "\n",
        "        # Process the visualization\n",
        "        magnitude = np.sqrt(np.sum(guided_bp_mask**2, axis=2))\n",
        "        magnitude = (magnitude - magnitude.min()) / (magnitude.max() - magnitude.min() + 1e-8)\n",
        "\n",
        "        high_threshold = np.percentile(magnitude, 98)\n",
        "        mid_threshold = np.percentile(magnitude, 90)\n",
        "\n",
        "        visualization = np.zeros((input_size, input_size, 3))\n",
        "        visualization[:,:,2] = magnitude\n",
        "        visualization[:,:,1] = magnitude * 0.8\n",
        "\n",
        "        red_mask = magnitude > high_threshold\n",
        "        blue_mask = (magnitude > mid_threshold) & (magnitude <= high_threshold)\n",
        "\n",
        "        visualization[red_mask, 0] = 1.0\n",
        "        visualization[red_mask, 1] = 0.2\n",
        "        visualization[red_mask, 2] = 0.2\n",
        "\n",
        "        visualization[blue_mask, 2] = 1.0\n",
        "        visualization[blue_mask, 1] = 0.8\n",
        "        visualization[blue_mask, 0] = 0.2\n",
        "\n",
        "        visualization = np.power(visualization, 0.7)\n",
        "\n",
        "        for i in range(3):\n",
        "            visualization[:,:,i] = gaussian_filter(visualization[:,:,i], sigma=1)\n",
        "\n",
        "        return visualization, confidence, prediction\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {str(e)}\")\n",
        "        return None, None, None"
      ],
      "metadata": {
        "id": "9IG1vkirOLPm"
      },
      "id": "9IG1vkirOLPm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First define your models dictionary\n",
        "models_dict = {\n",
        "    'ResNet50': resnet50_model,\n",
        "    'ResNet101': resnet101_model,\n",
        "    'EfficientNetB0': efficientnetb0_model,\n",
        "    'EfficientNetB1': efficientnetb1_model\n",
        "}\n",
        "\n",
        "# Define the images you want to process\n",
        "images_to_process = [\n",
        "    'Te-gl_0261',\n",
        "    'Te-gl_0037',\n",
        "    'Te-gl_0131',\n",
        "    'Te-me_0224',\n",
        "    'Te-me_0231',\n",
        "    'Te-me_0162',\n",
        "    'Te-pi_0205',\n",
        "    'Te-pi_0132',\n",
        "    'Te-pi_0110'\n",
        "]\n",
        "\n",
        "# Define your training order (class labels)\n",
        "training_order = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "# Clear any existing hooks before running\n",
        "for name, module in next(iter(models_dict.values())).named_modules():\n",
        "    if hasattr(module, '_forward_hooks'):\n",
        "        module._forward_hooks.clear()\n",
        "\n",
        "# Call the visualization function\n",
        "visualize_guided_bp(\n",
        "    models_dict=models_dict,\n",
        "    image_list=images_to_process,\n",
        "    test_folder='/content/drive/MyDrive/Colab Notebooks/Resized_Testing',\n",
        "    training_order=training_order\n",
        ")"
      ],
      "metadata": {
        "id": "lyYN7DyWOYu2"
      },
      "id": "lyYN7DyWOYu2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fen11CEkTclo",
      "metadata": {
        "id": "fen11CEkTclo"
      },
      "source": [
        "## GradCam and Guided BP together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Unh0BEmJTcux",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Unh0BEmJTcux"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import math\n",
        "from pytorch_grad_cam import GradCAM\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from scipy.ndimage import gaussian_filter\n",
        "\n",
        "class GuidedBackpropReLUModel:\n",
        "    def __init__(self, model, device):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.forward_relu_outputs = []\n",
        "        self.forward_hook_handles = []\n",
        "        self.backward_hook_handles = []\n",
        "        self._register_hooks()\n",
        "\n",
        "    def _register_hooks(self):\n",
        "        def hook_fn(module, grad_in, grad_out):\n",
        "            # If there's a negative gradient, change it to zero\n",
        "            if isinstance(grad_in, tuple):\n",
        "                return (torch.clamp(grad_in[0], min=0.0),)\n",
        "            return torch.clamp(grad_in, min=0.0)\n",
        "\n",
        "        def forward_hook_fn(module, input, output):\n",
        "            self.forward_relu_outputs.append(output)\n",
        "\n",
        "        # Register hooks\n",
        "        for module in self.model.modules():\n",
        "            if isinstance(module, torch.nn.ReLU):\n",
        "                self.forward_hook_handles.append(module.register_forward_hook(forward_hook_fn))\n",
        "                self.backward_hook_handles.append(module.register_backward_hook(hook_fn))\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.forward_relu_outputs = []\n",
        "        return self.model(x)\n",
        "\n",
        "    def cleanup(self):\n",
        "        for handle in self.forward_hook_handles:\n",
        "            handle.remove()\n",
        "        for handle in self.backward_hook_handles:\n",
        "            handle.remove()\n",
        "\n",
        "    def __call__(self, input_img, target_category=None):\n",
        "        self.model.zero_grad()\n",
        "        output = self.forward(input_img)\n",
        "\n",
        "        if target_category is None:\n",
        "            target_category = output.argmax().item()\n",
        "\n",
        "        # Create one hot output\n",
        "        one_hot = torch.zeros_like(output)\n",
        "        one_hot[0][target_category] = 1\n",
        "\n",
        "        output.backward(gradient=one_hot)\n",
        "\n",
        "        # Gradient with respect to input\n",
        "        gradient = input_img.grad.cpu().data.numpy()[0]\n",
        "        gradient = gradient.transpose((1, 2, 0))\n",
        "\n",
        "        return gradient\n",
        "\n",
        "def get_model_specific_params(model_name):\n",
        "    \"\"\"Returns model-specific parameters for GradCAM\"\"\"\n",
        "    params = {\n",
        "        'resnet50': {\n",
        "            'target_layer': 'layer4',\n",
        "            'input_size': 224,\n",
        "            'layer_getter': lambda model: model.layer4[-1]\n",
        "        },\n",
        "        'resnet101': {\n",
        "            'target_layer': 'layer4',\n",
        "            'input_size': 224,\n",
        "            'layer_getter': lambda model: model.layer4[-1]\n",
        "        },\n",
        "        'efficientnetb0': {\n",
        "            'target_layer': 'features.8',\n",
        "            'input_size': 224,\n",
        "            'layer_getter': lambda model: model.features[8]\n",
        "        },\n",
        "        'efficientnetb1': {\n",
        "            'target_layer': 'features.8',\n",
        "            'input_size': 240,\n",
        "            'layer_getter': lambda model: model.features[8]\n",
        "        }\n",
        "    }\n",
        "    return params[model_name]\n",
        "\n",
        "def get_guided_bp_for_resnet(model, image_path, training_order):\n",
        "    \"\"\"Generate Guided Backpropagation visualization for ResNet models\"\"\"\n",
        "    try:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        guided_bp_model = GuidedBackpropReLUModel(model=model, device=device)\n",
        "\n",
        "        image = Image.open(image_path)\n",
        "        if image.mode == 'L':\n",
        "            image = Image.merge('RGB', (image, image, image))\n",
        "\n",
        "        preprocess = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "        input_tensor.requires_grad = True\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "            prediction = torch.argmax(output).item()\n",
        "            confidence = probabilities[0][prediction].item() * 100\n",
        "\n",
        "        guided_bp_mask = guided_bp_model(input_tensor, target_category=prediction)\n",
        "        guided_bp_model.cleanup()\n",
        "\n",
        "        if isinstance(guided_bp_mask, torch.Tensor):\n",
        "            guided_bp_mask = guided_bp_mask.cpu().numpy()\n",
        "\n",
        "        magnitude = np.sqrt(np.sum(guided_bp_mask**2, axis=2))\n",
        "        magnitude = (magnitude - magnitude.min()) / (magnitude.max() - magnitude.min() + 1e-8)\n",
        "\n",
        "        high_threshold = np.percentile(magnitude, 98)\n",
        "        mid_threshold = np.percentile(magnitude, 90)\n",
        "\n",
        "        visualization = np.zeros((224, 224, 3))\n",
        "        visualization[:,:,2] = magnitude\n",
        "        visualization[:,:,1] = magnitude * 0.8\n",
        "\n",
        "        red_mask = magnitude > high_threshold\n",
        "        blue_mask = (magnitude > mid_threshold) & (magnitude <= high_threshold)\n",
        "\n",
        "        visualization[red_mask, 0] = 1.0\n",
        "        visualization[red_mask, 1] = 0.2\n",
        "        visualization[red_mask, 2] = 0.2\n",
        "\n",
        "        visualization[blue_mask, 2] = 1.0\n",
        "        visualization[blue_mask, 1] = 0.8\n",
        "        visualization[blue_mask, 0] = 0.2\n",
        "\n",
        "        visualization = np.power(visualization, 0.7)\n",
        "\n",
        "        for i in range(3):\n",
        "            visualization[:,:,i] = gaussian_filter(visualization[:,:,i], sigma=1)\n",
        "\n",
        "        return visualization, confidence, prediction\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {str(e)}\")\n",
        "        return None, None, None\n",
        "\n",
        "def get_guided_bp_for_efficientnet(model, image_path, input_size, training_order):\n",
        "    \"\"\"Generate Guided Backpropagation visualization for EfficientNet models\"\"\"\n",
        "    try:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "\n",
        "        guided_bp_model = GuidedBackpropReLUModel(model=model, device=device)\n",
        "\n",
        "        image = Image.open(image_path)\n",
        "        if image.mode == 'L':\n",
        "            image = Image.merge('RGB', (image, image, image))\n",
        "\n",
        "        preprocess = transforms.Compose([\n",
        "            transforms.Resize((input_size, input_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        input_tensor = preprocess(image).unsqueeze(0).to(device)\n",
        "        input_tensor.requires_grad = True\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "            prediction = torch.argmax(output).item()\n",
        "            confidence = probabilities[0][prediction].item() * 100\n",
        "\n",
        "        guided_bp_mask = guided_bp_model(input_tensor, target_category=prediction)\n",
        "        guided_bp_model.cleanup()\n",
        "\n",
        "        if isinstance(guided_bp_mask, torch.Tensor):\n",
        "            guided_bp_mask = guided_bp_mask.cpu().numpy()\n",
        "\n",
        "        magnitude = np.sqrt(np.sum(guided_bp_mask**2, axis=2))\n",
        "        magnitude = (magnitude - magnitude.min()) / (magnitude.max() - magnitude.min() + 1e-8)\n",
        "\n",
        "        high_threshold = np.percentile(magnitude, 98)\n",
        "        mid_threshold = np.percentile(magnitude, 90)\n",
        "\n",
        "        visualization = np.zeros((input_size, input_size, 3))\n",
        "        visualization[:,:,2] = magnitude\n",
        "        visualization[:,:,1] = magnitude * 0.8\n",
        "\n",
        "        red_mask = magnitude > high_threshold\n",
        "        blue_mask = (magnitude > mid_threshold) & (magnitude <= high_threshold)\n",
        "\n",
        "        visualization[red_mask, 0] = 1.0\n",
        "        visualization[red_mask, 1] = 0.2\n",
        "        visualization[red_mask, 2] = 0.2\n",
        "\n",
        "        visualization[blue_mask, 2] = 1.0\n",
        "        visualization[blue_mask, 1] = 0.8\n",
        "        visualization[blue_mask, 0] = 0.2\n",
        "\n",
        "        visualization = np.power(visualization, 0.7)\n",
        "\n",
        "        for i in range(3):\n",
        "            visualization[:,:,i] = gaussian_filter(visualization[:,:,i], sigma=1)\n",
        "\n",
        "        return visualization, confidence, prediction\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {str(e)}\")\n",
        "        return None, None, None\n",
        "\n",
        "def get_gradcam_for_image(model, model_name, image_path, training_order):\n",
        "    \"\"\"Generate GradCAM visualization for a single model and image\"\"\"\n",
        "    try:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = model.to(device)\n",
        "        model_params = get_model_specific_params(model_name)\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((model_params['input_size'], model_params['input_size'])),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        target_layer = model_params['layer_getter'](model)\n",
        "        grad_cam = GradCAM(\n",
        "            model=model,\n",
        "            target_layers=[target_layer],\n",
        "            reshape_transform=None\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "            prediction = torch.argmax(output).item()\n",
        "            confidence = probabilities[0][prediction].item() * 100\n",
        "\n",
        "        targets = [ClassifierOutputTarget(prediction)]\n",
        "        grayscale_cam = grad_cam(input_tensor=input_tensor, targets=targets)\n",
        "        grayscale_cam = grayscale_cam[0, :]\n",
        "\n",
        "        rgb_img = np.array(image.resize((model_params['input_size'], model_params['input_size']))) / 255.0\n",
        "        visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
        "\n",
        "        return visualization, confidence, prediction\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path} with {model_name}: {str(e)}\")\n",
        "        return None, None, None\n",
        "\n",
        "def visualize_all_methods(models_dict, image_list, test_folder, training_order):\n",
        "    \"\"\"\n",
        "    Visualize both GradCAM and Guided Backpropagation for all models\n",
        "    \"\"\"\n",
        "    folder_map = {\n",
        "        'gl': 'glioma',\n",
        "        'me': 'meningioma',\n",
        "        'pi': 'pituitary'\n",
        "    }\n",
        "\n",
        "    n_images = len(image_list)\n",
        "    n_models = len(models_dict)\n",
        "    n_cols = 1 + 2 * n_models\n",
        "\n",
        "    plt.figure(figsize=(4 * n_cols, 3 * n_images))\n",
        "\n",
        "    for img_idx, img_name in enumerate(image_list):\n",
        "        category_short = img_name.split('-')[1].split('_')[0]\n",
        "        category_full = folder_map[category_short]\n",
        "        img_path = os.path.join(test_folder, category_full, img_name + '.jpg')\n",
        "\n",
        "        original_img = Image.open(img_path).convert('RGB')\n",
        "        plt.subplot(n_images, n_cols, img_idx * n_cols + 1)\n",
        "        plt.imshow(original_img)\n",
        "        plt.title(f'Original\\n{img_name}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        for model_idx, (model_name, model) in enumerate(models_dict.items(), 1):\n",
        "            gradcam_vis, gradcam_conf, gradcam_pred = get_gradcam_for_image(\n",
        "                model,\n",
        "                model_name.lower(),\n",
        "                img_path,\n",
        "                training_order\n",
        "            )\n",
        "\n",
        "            if model_name.startswith('EfficientNet'):\n",
        "                input_size = 224 if 'B0' in model_name else 240\n",
        "                guided_vis, guided_conf, guided_pred = get_guided_bp_for_efficientnet(\n",
        "                    model,\n",
        "                    img_path,\n",
        "                    input_size,\n",
        "                    training_order\n",
        "                )\n",
        "            else:\n",
        "                guided_vis, guided_conf, guided_pred = get_guided_bp_for_resnet(\n",
        "                    model,\n",
        "                    img_path,\n",
        "                    training_order\n",
        "                )\n",
        "\n",
        "            col_idx = 2 * model_idx\n",
        "            plt.subplot(n_images, n_cols, img_idx * n_cols + col_idx)\n",
        "            if gradcam_vis is not None:\n",
        "                plt.imshow(gradcam_vis)\n",
        "                plt.title(f'{model_name} GradCAM\\nConf: {gradcam_conf:.1f}%\\n'\n",
        "                         f'Pred: {training_order[gradcam_pred]}')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(n_images, n_cols, img_idx * n_cols + col_idx + 1)\n",
        "            if guided_vis is not None:\n",
        "                plt.imshow(guided_vis)\n",
        "                plt.title(f'{model_name} GuidedBP\\nConf: {guided_conf:.1f}%\\n'\n",
        "                         f'Pred: {training_order[guided_pred]}')\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Usage example:\n",
        "\n",
        "models_dict = {\n",
        "    'ResNet50': resnet50_model,\n",
        "    'ResNet101': resnet101_model,\n",
        "    'EfficientNetB0': efficientnetb0_model,\n",
        "    'EfficientNetB1': efficientnetb1_model\n",
        "}\n",
        "\n",
        "images_to_process = [\n",
        "    'Te-gl_0261',\n",
        "    'Te-gl_0037',\n",
        "    'Te-gl_0131',\n",
        "    'Te-me_0224',\n",
        "    'Te-me_0231',\n",
        "    'Te-me_0162',\n",
        "    'Te-pi_0205',\n",
        "    'Te-pi_0132',\n",
        "    'Te-pi_0110'\n",
        "]\n",
        "\n",
        "training_order = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "# Clear any existing hooks\n",
        "for name, module in next(iter(models_dict.values())).named_modules():\n",
        "    if hasattr(module, '_forward_hooks'):\n",
        "        module._forward_hooks.clear()\n",
        "\n",
        "# Run visualization\n",
        "visualize_all_methods(\n",
        "    models_dict=models_dict,\n",
        "    image_list=images_to_process,\n",
        "    test_folder='/content/drive/MyDrive/Colab Notebooks/Resized_Testing',\n",
        "    training_order=training_order\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gF5UZKFUTcxm",
      "metadata": {
        "id": "gF5UZKFUTcxm"
      },
      "outputs": [],
      "source": [
        "def visualize_all_methods_organized(models_dict, image_list, test_folder, training_order):\n",
        "    \"\"\"\n",
        "    Visualize both GradCAM and Guided Backpropagation for all models,\n",
        "    organizing each model's results on a separate row\n",
        "    \"\"\"\n",
        "    folder_map = {\n",
        "        'gl': 'glioma',\n",
        "        'me': 'meningioma',\n",
        "        'pi': 'pituitary'\n",
        "    }\n",
        "\n",
        "    n_images = len(image_list)\n",
        "    n_models = len(models_dict)\n",
        "    n_cols = 3  # Original + GradCAM + GuidedBP\n",
        "    n_rows_per_image = n_models + 1  # One row per model plus original image row\n",
        "\n",
        "    plt.figure(figsize=(12, 3 * n_images * n_rows_per_image))\n",
        "\n",
        "    for img_idx, img_name in enumerate(image_list):\n",
        "        base_row = img_idx * n_rows_per_image\n",
        "        category_short = img_name.split('-')[1].split('_')[0]\n",
        "        category_full = folder_map[category_short]\n",
        "        img_path = os.path.join(test_folder, category_full, img_name + '.jpg')\n",
        "\n",
        "        # Load original image\n",
        "        original_img = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        # First row: Original image\n",
        "        plt.subplot(n_images * n_rows_per_image, n_cols, base_row * n_cols + 1)\n",
        "        plt.imshow(original_img)\n",
        "        plt.title(f'Original\\n{img_name}')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Hide empty plots in first row\n",
        "        plt.subplot(n_images * n_rows_per_image, n_cols, base_row * n_cols + 2)\n",
        "        plt.axis('off')\n",
        "        plt.subplot(n_images * n_rows_per_image, n_cols, base_row * n_cols + 3)\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Process each model in subsequent rows\n",
        "        for model_idx, (model_name, model) in enumerate(models_dict.items(), 1):\n",
        "            current_row = base_row + model_idx\n",
        "            row_start = current_row * n_cols + 1\n",
        "\n",
        "            # Get GradCAM visualization\n",
        "            gradcam_vis, gradcam_conf, gradcam_pred = get_gradcam_for_image(\n",
        "                model,\n",
        "                model_name.lower(),\n",
        "                img_path,\n",
        "                training_order\n",
        "            )\n",
        "\n",
        "            # Get Guided BP visualization\n",
        "            if model_name.startswith('EfficientNet'):\n",
        "                input_size = 224 if 'B0' in model_name else 240\n",
        "                guided_vis, guided_conf, guided_pred = get_guided_bp_for_efficientnet(\n",
        "                    model,\n",
        "                    img_path,\n",
        "                    input_size,\n",
        "                    training_order\n",
        "                )\n",
        "            else:\n",
        "                guided_vis, guided_conf, guided_pred = get_guided_bp_for_resnet(\n",
        "                    model,\n",
        "                    img_path,\n",
        "                    training_order\n",
        "                )\n",
        "\n",
        "            # Plot model name in first column\n",
        "            plt.subplot(n_images * n_rows_per_image, n_cols, row_start)\n",
        "            plt.text(0.5, 0.5, model_name, ha='center', va='center')\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Plot GradCAM\n",
        "            plt.subplot(n_images * n_rows_per_image, n_cols, row_start + 1)\n",
        "            if gradcam_vis is not None:\n",
        "                plt.imshow(gradcam_vis)\n",
        "                plt.title(f'GradCAM\\nConf: {gradcam_conf:.1f}%\\n'\n",
        "                         f'Pred: {training_order[gradcam_pred]}')\n",
        "            plt.axis('off')\n",
        "\n",
        "            # Plot Guided BP\n",
        "            plt.subplot(n_images * n_rows_per_image, n_cols, row_start + 2)\n",
        "            if guided_vis is not None:\n",
        "                plt.imshow(guided_vis)\n",
        "                plt.title(f'GuidedBP\\nConf: {guided_conf:.1f}%\\n'\n",
        "                         f'Pred: {training_order[guided_pred]}')\n",
        "            plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Usage:\n",
        "models_dict = {\n",
        "    'ResNet50': resnet50_model,\n",
        "    'ResNet101': resnet101_model,\n",
        "    'EfficientNetB0': efficientnetb0_model,\n",
        "    'EfficientNetB1': efficientnetb1_model\n",
        "}\n",
        "\n",
        "# Clear any existing hooks\n",
        "for name, module in next(iter(models_dict.values())).named_modules():\n",
        "    if hasattr(module, '_forward_hooks'):\n",
        "        module._forward_hooks.clear()\n",
        "\n",
        "# Run visualization\n",
        "visualize_all_methods_organized(\n",
        "    models_dict=models_dict,\n",
        "    image_list=images_to_process,\n",
        "    test_folder='/content/drive/MyDrive/Colab Notebooks/Resized_Testing',\n",
        "    training_order=training_order\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "D0KROVZu32RD",
      "metadata": {
        "id": "D0KROVZu32RD"
      },
      "source": [
        "## Attention roll out and Beyond Attention for Vit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vit_model = initialize_vit_model(num_classes=len(tumor_types))\n",
        "vit_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/final_vit_small_mri_classification_model.pth'))\n",
        "vit_model.eval()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gi0wGk4KS8wE"
      },
      "id": "gi0wGk4KS8wE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8i4YaNEPPZNJ",
      "metadata": {
        "id": "8i4YaNEPPZNJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import transforms\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class VitAttentionRollout:\n",
        "    def __init__(self, model, device='cuda'):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.attention_layers = []\n",
        "        self.hooks = []\n",
        "\n",
        "    def register_hooks(self):\n",
        "        def hook_fn(name):\n",
        "            def hook(module, input, output):\n",
        "                with torch.no_grad():\n",
        "                    B, N, C = output.shape\n",
        "                    num_heads = self.model.blocks[0].attn.num_heads\n",
        "                    head_dim = C // (3 * num_heads)\n",
        "\n",
        "                    qkv = output.reshape(B, N, 3, num_heads, head_dim)\n",
        "                    qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "                    q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "                    attn = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(head_dim))\n",
        "                    attn = torch.nn.functional.softmax(attn, dim=-1)\n",
        "                    self.attention_layers.append(attn.detach())\n",
        "            return hook\n",
        "\n",
        "        for block in self.model.blocks:\n",
        "            self.hooks.append(block.attn.qkv.register_forward_hook(hook_fn(\"attn\")))\n",
        "\n",
        "    def cleanup(self):\n",
        "        for hook in self.hooks:\n",
        "            hook.remove()\n",
        "        self.hooks = []\n",
        "\n",
        "    def get_attention_rollout(self, input_tensor):\n",
        "        self.attention_layers = []\n",
        "        self.cleanup()\n",
        "        self.register_hooks()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            _ = self.model(input_tensor)\n",
        "\n",
        "        self.cleanup()\n",
        "\n",
        "        attention_maps = [attn.mean(dim=1) for attn in self.attention_layers]\n",
        "        flat_attn = attention_maps[0]\n",
        "        for attn in attention_maps[1:]:\n",
        "            flat_attn = torch.matmul(attn, flat_attn)\n",
        "\n",
        "        attention = flat_attn[0, 1:, 1:]\n",
        "        attention = attention.mean(dim=-1)\n",
        "\n",
        "        grid_size = int(math.sqrt(attention.shape[0]))\n",
        "        attention = attention.reshape(grid_size, grid_size).cpu().numpy()\n",
        "\n",
        "        attention = (attention - attention.min()) / (attention.max() - attention.min())\n",
        "\n",
        "        return attention\n",
        "\n",
        "class VitBeyondAttention:\n",
        "    def __init__(self, model, device='cuda', discard_ratio=0.9):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.attention_layers = []\n",
        "        self.hooks = []\n",
        "        self.discard_ratio = discard_ratio\n",
        "\n",
        "    def register_hooks(self):\n",
        "        def hook_fn(name):\n",
        "            def hook(module, input, output):\n",
        "                with torch.no_grad():\n",
        "                    B, N, C = output.shape\n",
        "                    num_heads = self.model.blocks[0].attn.num_heads\n",
        "                    head_dim = C // (3 * num_heads)\n",
        "\n",
        "                    qkv = output.reshape(B, N, 3, num_heads, head_dim)\n",
        "                    qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "                    q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "                    attn = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(head_dim))\n",
        "                    attn = torch.nn.functional.softmax(attn, dim=-1)\n",
        "                    self.attention_layers.append(attn.detach())\n",
        "            return hook\n",
        "\n",
        "        for block in self.model.blocks:\n",
        "            self.hooks.append(block.attn.qkv.register_forward_hook(hook_fn(\"attn\")))\n",
        "\n",
        "    def cleanup(self):\n",
        "        for hook in self.hooks:\n",
        "            hook.remove()\n",
        "        self.hooks = []\n",
        "\n",
        "    def get_beyond_attention(self, input_tensor):\n",
        "        self.attention_layers = []\n",
        "        self.cleanup()\n",
        "        self.register_hooks()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            _ = self.model(input_tensor)\n",
        "\n",
        "        self.cleanup()\n",
        "\n",
        "        attention_maps = [attn.mean(dim=1) for attn in self.attention_layers]\n",
        "        attention_maps = [F.relu(attn) for attn in attention_maps]\n",
        "\n",
        "        for attn in attention_maps:\n",
        "            flat_attn = attn.view(-1)\n",
        "            threshold = torch.sort(flat_attn)[0][int(flat_attn.shape[0] * self.discard_ratio)]\n",
        "            attn[attn < threshold] = 0\n",
        "\n",
        "        flat_attn = attention_maps[0]\n",
        "        for attn in attention_maps[1:]:\n",
        "            flat_attn = torch.matmul(attn, flat_attn)\n",
        "\n",
        "        eye = torch.eye(flat_attn.shape[-1], device=flat_attn.device)\n",
        "        flat_attn = flat_attn + eye\n",
        "        flat_attn = flat_attn / flat_attn.sum(dim=-1, keepdim=True)\n",
        "\n",
        "        attention = flat_attn[0, 1:, 1:]\n",
        "        attention = attention.mean(dim=-1)\n",
        "\n",
        "        grid_size = int(math.sqrt(attention.shape[0]))\n",
        "        attention = attention.reshape(grid_size, grid_size).cpu().numpy()\n",
        "\n",
        "        attention = (attention - attention.min()) / (attention.max() - attention.min())\n",
        "\n",
        "        return attention\n",
        "\n",
        "def clear_hooks(model):\n",
        "    \"\"\"Clear any existing hooks from the model\"\"\"\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, '_forward_hooks'):\n",
        "            module._forward_hooks.clear()\n",
        "\n",
        "def create_attention_overlay(image, attention_map, alpha=0.6):\n",
        "    \"\"\"Create a bright attention overlay with jet colormap\"\"\"\n",
        "    heatmap = plt.cm.jet(attention_map)[:, :, :3]\n",
        "    heatmap = np.clip(heatmap * 1.2, 0, 1)\n",
        "    overlay = image * (1 - alpha) + heatmap * alpha\n",
        "    return np.clip(overlay, 0, 1)\n",
        "\n",
        "def visualize_combined_attention(model, image_path, training_order=None, discard_ratio=0.9):\n",
        "    \"\"\"\n",
        "    Visualize both attention rollout and beyond attention overlays for a ViT model\n",
        "\n",
        "    Args:\n",
        "        model: ViT model\n",
        "        image_path: Path to input image\n",
        "        training_order: Optional list of class names\n",
        "        discard_ratio: Ratio for discarding low attention weights in beyond attention\n",
        "\n",
        "    Returns:\n",
        "        tuple: (rollout_map, beyond_map, prediction, confidence)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        model = model.to(device)\n",
        "\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "            prediction = torch.argmax(output).item()\n",
        "            confidence = probabilities[0][prediction].item() * 100\n",
        "\n",
        "        clear_hooks(model)\n",
        "\n",
        "        attention_rollout = VitAttentionRollout(model, device=device)\n",
        "        rollout_map = attention_rollout.get_attention_rollout(input_tensor)\n",
        "\n",
        "        clear_hooks(model)\n",
        "\n",
        "        beyond_attention = VitBeyondAttention(model, device=device, discard_ratio=discard_ratio)\n",
        "        beyond_map = beyond_attention.get_beyond_attention(input_tensor)\n",
        "\n",
        "        def resize_map(attention_map):\n",
        "            return F.interpolate(\n",
        "                torch.tensor(attention_map).unsqueeze(0).unsqueeze(0),\n",
        "                size=(224, 224),\n",
        "                mode='bilinear',\n",
        "                align_corners=False\n",
        "            ).squeeze().numpy()\n",
        "\n",
        "        rollout_map = resize_map(rollout_map)\n",
        "        beyond_map = resize_map(beyond_map)\n",
        "\n",
        "        img_np = np.array(image.resize((224, 224))) / 255.0\n",
        "\n",
        "        rollout_overlay = create_attention_overlay(img_np, rollout_map)\n",
        "        beyond_overlay = create_attention_overlay(img_np, beyond_map)\n",
        "\n",
        "        # Smaller figure size\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        # Original image\n",
        "        plt.subplot(131)\n",
        "        plt.imshow(image)\n",
        "        plt.title('Original Image')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Attention rollout overlay\n",
        "        plt.subplot(132)\n",
        "        plt.imshow(rollout_overlay)\n",
        "        plt.title('Attention Rollout')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Beyond attention overlay\n",
        "        plt.subplot(133)\n",
        "        plt.imshow(beyond_overlay)\n",
        "        plt.title('Beyond Attention')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Add prediction text to the bottom of the figure\n",
        "        plt.figtext(0.5, 0.02,\n",
        "                   f\"Prediction: {training_order[prediction] if training_order else prediction} (Confidence: {confidence:.1f}%)\",\n",
        "                   ha='center', va='center')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        return rollout_map, beyond_map, prediction, confidence\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {str(e)}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None, None, None, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m_KtnqP6PaSv",
      "metadata": {
        "id": "m_KtnqP6PaSv"
      },
      "outputs": [],
      "source": [
        "# Clear any existing hooks first\n",
        "clear_hooks(vit_model)\n",
        "\n",
        "# Use your actual image path\n",
        "img_path = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing/glioma/Te-gl_0261.jpg'\n",
        "rollout_map, beyond_map, pred, conf = visualize_combined_attention(vit_model, img_path, tumor_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DvNToZSOSBJz",
      "metadata": {
        "id": "DvNToZSOSBJz"
      },
      "outputs": [],
      "source": [
        "def get_image_path(base_path, img_name):\n",
        "    \"\"\"Helper function to construct the correct image path based on name prefix\"\"\"\n",
        "    if 'gl' in img_name:\n",
        "        subfolder = 'glioma'\n",
        "    elif 'me' in img_name:\n",
        "        subfolder = 'meningioma'\n",
        "    elif 'pi' in img_name:\n",
        "        subfolder = 'pituitary'\n",
        "    return f\"{base_path}/{subfolder}/{img_name}.jpg\"\n",
        "\n",
        "def visualize_batch_attention(model, image_names, base_path, training_order=None, discard_ratio=0.9):\n",
        "    \"\"\"\n",
        "    Visualize attention for multiple images with smaller figure size\n",
        "    \"\"\"\n",
        "    for idx, img_name in enumerate(image_names):\n",
        "        try:\n",
        "            img_path = get_image_path(base_path, img_name)\n",
        "\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            model = model.to(device)\n",
        "\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "            ])\n",
        "\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = model(input_tensor)\n",
        "                probabilities = torch.nn.functional.softmax(output, dim=1)\n",
        "                prediction = torch.argmax(output).item()\n",
        "                confidence = probabilities[0][prediction].item() * 100\n",
        "\n",
        "            clear_hooks(model)\n",
        "            attention_rollout = VitAttentionRollout(model, device=device)\n",
        "            rollout_map = attention_rollout.get_attention_rollout(input_tensor)\n",
        "\n",
        "            clear_hooks(model)\n",
        "            beyond_attention = VitBeyondAttention(model, device=device, discard_ratio=discard_ratio)\n",
        "            beyond_map = beyond_attention.get_beyond_attention(input_tensor)\n",
        "\n",
        "            def resize_map(attention_map):\n",
        "                return F.interpolate(\n",
        "                    torch.tensor(attention_map).unsqueeze(0).unsqueeze(0),\n",
        "                    size=(224, 224),\n",
        "                    mode='bilinear',\n",
        "                    align_corners=False\n",
        "                ).squeeze().numpy()\n",
        "\n",
        "            rollout_map = resize_map(rollout_map)\n",
        "            beyond_map = resize_map(beyond_map)\n",
        "\n",
        "            img_np = np.array(image.resize((224, 224))) / 255.0\n",
        "            rollout_overlay = create_attention_overlay(img_np, rollout_map)\n",
        "            beyond_overlay = create_attention_overlay(img_np, beyond_map)\n",
        "\n",
        "            # Reduced figure size from (12, 4) to (9, 3)\n",
        "            fig_local = plt.figure(figsize=(9, 3))\n",
        "\n",
        "            plt.subplot(131)\n",
        "            plt.imshow(image)\n",
        "            plt.title('Original')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(132)\n",
        "            plt.imshow(rollout_overlay)\n",
        "            plt.title('Rollout')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(133)\n",
        "            plt.imshow(beyond_overlay)\n",
        "            plt.title('Beyond')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.figtext(0.5, 0.02,\n",
        "                       f\"{img_name}\\nPred: {training_order[prediction] if training_order else prediction} ({confidence:.1f}%)\",\n",
        "                       ha='center', va='center')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "            plt.close(fig_local)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {img_name}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "\n",
        "# Usage example:\n",
        "base_path = '/content/drive/MyDrive/Colab Notebooks/Resized_Testing'\n",
        "images_to_process = [\n",
        "    'Te-gl_0261',\n",
        "    'Te-gl_0037',\n",
        "    'Te-gl_0131',\n",
        "    'Te-me_0224',\n",
        "    'Te-me_0231',\n",
        "    'Te-me_0162',\n",
        "    'Te-pi_0205',\n",
        "    'Te-pi_0132',\n",
        "    'Te-pi_0110'\n",
        "]\n",
        "\n",
        "# Clear any existing hooks\n",
        "clear_hooks(vit_model)\n",
        "\n",
        "# Process all images\n",
        "visualize_batch_attention(vit_model, images_to_process, base_path, tumor_types)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}